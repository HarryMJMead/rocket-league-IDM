{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import numpy as np\n",
    "import wandb\n",
    "import os\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from lib.data import EpisodeDataset, EpisodeDataset_Unmodified\n",
    "from lib.neural_networks import FullyConnected_Continuous, FullyConnected_Continuous_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 5\n",
    "OBS_SIZE = 30 #46 is standard, 15 is minimal\n",
    "HIDDEN_SIZE = 2048\n",
    "\n",
    "INCLUDE_CHANGE = True\n",
    "CORRUPT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Episode Data\n",
      "Finished Loading Episode Data\n",
      "125820\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH_1 = '/data/hmead/Episode Data/Continuous Random Data/30 TPS/3v3 Train'\n",
    "\n",
    "train_dataset = EpisodeDataset_Unmodified([TRAIN_PATH_1], width=WIDTH, include_change=INCLUDE_CHANGE, corrupt=CORRUPT)\n",
    "\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data_Loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=32, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Episode Data\n",
      "Finished Loading Episode Data\n",
      "Loading Episode Data\n",
      "Finished Loading Episode Data\n",
      "Loading Episode Data\n",
      "Finished Loading Episode Data\n",
      "180\n",
      "180\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "TEST_PATH_UNFILTERED = '/data/hmead/Episode Data/Continuous Random Data Unfiltered/30 TPS/3v3 Test'\n",
    "TEST_PATH = '/data/hmead/Episode Data/Continuous Random Data/30 TPS/3v3 Test'\n",
    "TEST_PATH_HUMAN = '/data/hmead/Episode Data/Human Example Data/30 TPS'\n",
    "\n",
    "\n",
    "test_dataset_unfiltered = EpisodeDataset_Unmodified([TEST_PATH_UNFILTERED], width=WIDTH, include_change=INCLUDE_CHANGE, corrupt=CORRUPT)\n",
    "test_dataset = EpisodeDataset_Unmodified([TEST_PATH], width=WIDTH, include_change=INCLUDE_CHANGE, corrupt=CORRUPT)\n",
    "test_dataset_human = EpisodeDataset_Unmodified([TEST_PATH_HUMAN], width=WIDTH, include_change=INCLUDE_CHANGE, corrupt=CORRUPT)\n",
    "\n",
    "\n",
    "print(len(test_dataset_unfiltered))\n",
    "print(len(test_dataset))\n",
    "print(len(test_dataset_human))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data_Loader_Unfiltered = DataLoader(test_dataset_unfiltered, batch_size=1, shuffle=False, num_workers=1)\n",
    "Test_Data_Loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "Test_Data_Loader_Human = DataLoader(test_dataset_human, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ConvNet(obs_size=OBS_SIZE, obs_width=WIDTH, conv_number=10, hidden_size=HIDDEN_SIZE)\n",
    "model = FullyConnected_Continuous_2(obs_size=OBS_SIZE, obs_width=WIDTH, hidden_size=HIDDEN_SIZE)\n",
    "\n",
    "gpumodel = model.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(gpumodel.parameters(), lr=0.0001)\n",
    "#scheduler = ExponentialLR(optimizer, gamma = 0.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpumodel.load_state_dict(torch.load('trained_networks/mild-wood-119.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(gpumodel, Test_Data_Loader):\n",
    "    gpumodel.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    obs_count = 0\n",
    "\n",
    "    for _obs, _act, _add_data in Test_Data_Loader:\n",
    "        # EVALUATION\n",
    "        obs = _obs[0].cuda()\n",
    "        act = _act[0, :, 0:5].float().cuda()\n",
    "\n",
    "        if obs.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(obs)\n",
    "\n",
    "        loss = criterion(y_pred, act)\n",
    "\n",
    "        # LOGGING\n",
    "        obs_count += len(obs)\n",
    "        total_loss += loss.item() * len(obs)\n",
    "\n",
    "    return total_loss / obs_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cfo9mcn0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss_MSE</td><td>█▆▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss_MSE</td><td>█▆▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss_human_MSE</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▁▁▁▂▁▁▂▂▁▁▁▁▂▁</td></tr><tr><td>test_loss_unfiltered_MSE</td><td>█▅▄▄▅▃▃▁▂▂▁▁▂▂▁▂▁▁▁▂▂▂▂▂▁▂▁▂▂▂▂▂▂▂▂▁▃▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss_MSE</td><td>0.04743</td></tr><tr><td>test_loss_MSE</td><td>0.05162</td></tr><tr><td>test_loss_human_MSE</td><td>0.08279</td></tr><tr><td>test_loss_unfiltered_MSE</td><td>0.30888</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stilted-capybara-17</strong> at: <a href='https://wandb.ai/harrymead/Inverse%20Dynamics%20Model%20Retest/runs/cfo9mcn0' target=\"_blank\">https://wandb.ai/harrymead/Inverse%20Dynamics%20Model%20Retest/runs/cfo9mcn0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230427_190632-cfo9mcn0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cfo9mcn0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hmead/Rocket League Behaviour Cloning/rocket-league-IDM/wandb/run-20230427_224102-u4o08pnr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/harrymead/Inverse%20Dynamics%20Model%20Retest/runs/u4o08pnr' target=\"_blank\">confused-serenity-18</a></strong> to <a href='https://wandb.ai/harrymead/Inverse%20Dynamics%20Model%20Retest' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/harrymead/Inverse%20Dynamics%20Model%20Retest' target=\"_blank\">https://wandb.ai/harrymead/Inverse%20Dynamics%20Model%20Retest</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/harrymead/Inverse%20Dynamics%20Model%20Retest/runs/u4o08pnr' target=\"_blank\">https://wandb.ai/harrymead/Inverse%20Dynamics%20Model%20Retest/runs/u4o08pnr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"Inverse Dynamics Model Retest\", entity=\"harrymead\")\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.0001,\n",
    "  \"epochs\": 10,\n",
    "  \"batch_size\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.1515716114217394, Test Loss Unfiltered: 0.32164698179778417, Test Loss: 0.11128946760630808\n",
      "Epoch 1 - Loss: 0.1023655923355818, Test Loss Unfiltered: 0.32164698179778417, Test Loss: 0.11128946760630808\n",
      "Epoch 1 - Loss: 0.087814518914897, Test Loss Unfiltered: 0.32164698179778417, Test Loss: 0.11128946760630808\n",
      "Epoch 1 - Loss: 0.08119788926482034, Test Loss Unfiltered: 0.32164698179778417, Test Loss: 0.11128946760630808\n",
      "Epoch 1 - Loss: 0.07567844624587301, Test Loss Unfiltered: 0.32164698179778417, Test Loss: 0.11128946760630808\n",
      "Epoch 1 - Loss: 0.07381480685570897, Test Loss Unfiltered: 0.3046861676444733, Test Loss: 0.06839173380105829\n",
      "Epoch 1 - Loss: 0.07111509199248346, Test Loss Unfiltered: 0.3046861676444733, Test Loss: 0.06839173380105829\n",
      "Epoch 1 - Loss: 0.06849870844238812, Test Loss Unfiltered: 0.3046861676444733, Test Loss: 0.06839173380105829\n",
      "Epoch 1 - Loss: 0.0668548161974949, Test Loss Unfiltered: 0.3046861676444733, Test Loss: 0.06839173380105829\n",
      "Epoch 1 - Loss: 0.065440433005235, Test Loss Unfiltered: 0.3046861676444733, Test Loss: 0.06839173380105829\n",
      "Epoch 1 - Loss: 0.06424947523238252, Test Loss Unfiltered: 0.30419763020810564, Test Loss: 0.05920092646028535\n",
      "Epoch 1 - Loss: 0.06340266982359755, Test Loss Unfiltered: 0.30419763020810564, Test Loss: 0.05920092646028535\n",
      "Epoch 1 - Loss: 0.06331005718627528, Test Loss Unfiltered: 0.30419763020810564, Test Loss: 0.05920092646028535\n",
      "Epoch 1 - Loss: 0.06125678286400582, Test Loss Unfiltered: 0.30419763020810564, Test Loss: 0.05920092646028535\n",
      "Epoch 1 - Loss: 0.059914380801364325, Test Loss Unfiltered: 0.30419763020810564, Test Loss: 0.05920092646028535\n",
      "Epoch 1 - Loss: 0.05874788101526868, Test Loss Unfiltered: 0.30517654420320334, Test Loss: 0.05566105557048736\n",
      "Epoch 1 - Loss: 0.05800921830526328, Test Loss Unfiltered: 0.30517654420320334, Test Loss: 0.05566105557048736\n",
      "Epoch 1 - Loss: 0.058307680232789524, Test Loss Unfiltered: 0.30517654420320334, Test Loss: 0.05566105557048736\n",
      "Epoch 1 - Loss: 0.057034124106958226, Test Loss Unfiltered: 0.30517654420320334, Test Loss: 0.05566105557048736\n",
      "Epoch 1 - Loss: 0.05720914721871731, Test Loss Unfiltered: 0.30517654420320334, Test Loss: 0.05566105557048736\n",
      "Epoch 1 - Loss: 0.056549972115286555, Test Loss Unfiltered: 0.3028411093266091, Test Loss: 0.052306398851592946\n",
      "Epoch 1 - Loss: 0.055811832517550994, Test Loss Unfiltered: 0.3028411093266091, Test Loss: 0.052306398851592946\n",
      "Epoch 1 - Loss: 0.05466279052530576, Test Loss Unfiltered: 0.3028411093266091, Test Loss: 0.052306398851592946\n",
      "Epoch 1 - Loss: 0.05564309036312929, Test Loss Unfiltered: 0.3028411093266091, Test Loss: 0.052306398851592946\n",
      "Epoch 1 - Loss: 0.053775807192763175, Test Loss Unfiltered: 0.3028411093266091, Test Loss: 0.052306398851592946\n",
      "Epoch 2 - Loss: 0.05332831974259469, Test Loss Unfiltered: 0.30581506727757585, Test Loss: 0.04992148878866578\n",
      "Epoch 2 - Loss: 0.05271997011995862, Test Loss Unfiltered: 0.30581506727757585, Test Loss: 0.04992148878866578\n",
      "Epoch 2 - Loss: 0.05246131462837822, Test Loss Unfiltered: 0.30581506727757585, Test Loss: 0.04992148878866578\n",
      "Epoch 2 - Loss: 0.05235404564871423, Test Loss Unfiltered: 0.30581506727757585, Test Loss: 0.04992148878866578\n",
      "Epoch 2 - Loss: 0.051632025163280366, Test Loss Unfiltered: 0.30581506727757585, Test Loss: 0.04992148878866578\n",
      "Epoch 2 - Loss: 0.05187415272174037, Test Loss Unfiltered: 0.30295706913486065, Test Loss: 0.04852898463673978\n",
      "Epoch 2 - Loss: 0.051316441965793845, Test Loss Unfiltered: 0.30295706913486065, Test Loss: 0.04852898463673978\n",
      "Epoch 2 - Loss: 0.05079954481966892, Test Loss Unfiltered: 0.30295706913486065, Test Loss: 0.04852898463673978\n",
      "Epoch 2 - Loss: 0.050787635072355015, Test Loss Unfiltered: 0.30295706913486065, Test Loss: 0.04852898463673978\n",
      "Epoch 2 - Loss: 0.050141155650676374, Test Loss Unfiltered: 0.30295706913486065, Test Loss: 0.04852898463673978\n",
      "Epoch 2 - Loss: 0.05010769973618109, Test Loss Unfiltered: 0.3036713581954168, Test Loss: 0.047907696542441064\n",
      "Epoch 2 - Loss: 0.04900838678375916, Test Loss Unfiltered: 0.3036713581954168, Test Loss: 0.047907696542441064\n",
      "Epoch 2 - Loss: 0.04968864748117711, Test Loss Unfiltered: 0.3036713581954168, Test Loss: 0.047907696542441064\n",
      "Epoch 2 - Loss: 0.048730859815236165, Test Loss Unfiltered: 0.3036713581954168, Test Loss: 0.047907696542441064\n",
      "Epoch 2 - Loss: 0.048952679914500606, Test Loss Unfiltered: 0.3036713581954168, Test Loss: 0.047907696542441064\n",
      "Epoch 2 - Loss: 0.0486379253489638, Test Loss Unfiltered: 0.30260188688682926, Test Loss: 0.04679774332776996\n",
      "Epoch 2 - Loss: 0.048546421398343954, Test Loss Unfiltered: 0.30260188688682926, Test Loss: 0.04679774332776996\n",
      "Epoch 2 - Loss: 0.04764634947633587, Test Loss Unfiltered: 0.30260188688682926, Test Loss: 0.04679774332776996\n",
      "Epoch 2 - Loss: 0.04768295985806491, Test Loss Unfiltered: 0.30260188688682926, Test Loss: 0.04679774332776996\n",
      "Epoch 2 - Loss: 0.04753991262893993, Test Loss Unfiltered: 0.30260188688682926, Test Loss: 0.04679774332776996\n",
      "Epoch 2 - Loss: 0.046742252794116715, Test Loss Unfiltered: 0.3023321029357835, Test Loss: 0.0444548757002624\n",
      "Epoch 2 - Loss: 0.047215763205861926, Test Loss Unfiltered: 0.3023321029357835, Test Loss: 0.0444548757002624\n",
      "Epoch 2 - Loss: 0.046992443720544105, Test Loss Unfiltered: 0.3023321029357835, Test Loss: 0.0444548757002624\n",
      "Epoch 2 - Loss: 0.04607793308098945, Test Loss Unfiltered: 0.3023321029357835, Test Loss: 0.0444548757002624\n",
      "Epoch 2 - Loss: 0.04672494821841359, Test Loss Unfiltered: 0.3023321029357835, Test Loss: 0.0444548757002624\n",
      "Epoch 3 - Loss: 0.045469738394782876, Test Loss Unfiltered: 0.30097657664394745, Test Loss: 0.04472108178210196\n",
      "Epoch 3 - Loss: 0.044704404671776526, Test Loss Unfiltered: 0.30097657664394745, Test Loss: 0.04472108178210196\n",
      "Epoch 3 - Loss: 0.04524101511807438, Test Loss Unfiltered: 0.30097657664394745, Test Loss: 0.04472108178210196\n",
      "Epoch 3 - Loss: 0.045205166783208316, Test Loss Unfiltered: 0.30097657664394745, Test Loss: 0.04472108178210196\n",
      "Epoch 3 - Loss: 0.045099676842084074, Test Loss Unfiltered: 0.30097657664394745, Test Loss: 0.04472108178210196\n",
      "Epoch 3 - Loss: 0.04491307208349166, Test Loss Unfiltered: 0.30296781708970766, Test Loss: 0.043481206274082765\n",
      "Epoch 3 - Loss: 0.04469199076367589, Test Loss Unfiltered: 0.30296781708970766, Test Loss: 0.043481206274082765\n",
      "Epoch 3 - Loss: 0.044956395339290134, Test Loss Unfiltered: 0.30296781708970766, Test Loss: 0.043481206274082765\n",
      "Epoch 3 - Loss: 0.044257717715441895, Test Loss Unfiltered: 0.30296781708970766, Test Loss: 0.043481206274082765\n",
      "Epoch 3 - Loss: 0.04412498056778621, Test Loss Unfiltered: 0.30296781708970766, Test Loss: 0.043481206274082765\n",
      "Epoch 3 - Loss: 0.044181182946374895, Test Loss Unfiltered: 0.301336626730541, Test Loss: 0.04260689929864501\n",
      "Epoch 3 - Loss: 0.04393203205381772, Test Loss Unfiltered: 0.301336626730541, Test Loss: 0.04260689929864501\n",
      "Epoch 3 - Loss: 0.043914466191391374, Test Loss Unfiltered: 0.301336626730541, Test Loss: 0.04260689929864501\n",
      "Epoch 3 - Loss: 0.04366961637560499, Test Loss Unfiltered: 0.301336626730541, Test Loss: 0.04260689929864501\n",
      "Epoch 3 - Loss: 0.04308891556503712, Test Loss Unfiltered: 0.301336626730541, Test Loss: 0.04260689929864501\n",
      "Epoch 3 - Loss: 0.04361875925266833, Test Loss Unfiltered: 0.3020419429385787, Test Loss: 0.04159034496868475\n",
      "Epoch 3 - Loss: 0.043009543521027385, Test Loss Unfiltered: 0.3020419429385787, Test Loss: 0.04159034496868475\n",
      "Epoch 3 - Loss: 0.04349170445720255, Test Loss Unfiltered: 0.3020419429385787, Test Loss: 0.04159034496868475\n",
      "Epoch 3 - Loss: 0.04324662532714962, Test Loss Unfiltered: 0.3020419429385787, Test Loss: 0.04159034496868475\n",
      "Epoch 3 - Loss: 0.043153180078599265, Test Loss Unfiltered: 0.3020419429385787, Test Loss: 0.04159034496868475\n",
      "Epoch 3 - Loss: 0.042364372106677796, Test Loss Unfiltered: 0.30158739893511943, Test Loss: 0.041337632808873\n",
      "Epoch 3 - Loss: 0.042367393554938286, Test Loss Unfiltered: 0.30158739893511943, Test Loss: 0.041337632808873\n",
      "Epoch 3 - Loss: 0.042279479110234976, Test Loss Unfiltered: 0.30158739893511943, Test Loss: 0.041337632808873\n",
      "Epoch 3 - Loss: 0.04236293473865214, Test Loss Unfiltered: 0.30158739893511943, Test Loss: 0.041337632808873\n",
      "Epoch 3 - Loss: 0.042411460438344095, Test Loss Unfiltered: 0.30158739893511943, Test Loss: 0.041337632808873\n",
      "Epoch 4 - Loss: 0.04091202578388132, Test Loss Unfiltered: 0.3010265199372438, Test Loss: 0.040552373081087334\n",
      "Epoch 4 - Loss: 0.04133501594914683, Test Loss Unfiltered: 0.3010265199372438, Test Loss: 0.040552373081087334\n",
      "Epoch 4 - Loss: 0.0410390605427032, Test Loss Unfiltered: 0.3010265199372438, Test Loss: 0.040552373081087334\n",
      "Epoch 4 - Loss: 0.04113267462963386, Test Loss Unfiltered: 0.3010265199372438, Test Loss: 0.040552373081087334\n",
      "Epoch 4 - Loss: 0.04049821263615134, Test Loss Unfiltered: 0.3010265199372438, Test Loss: 0.040552373081087334\n",
      "Epoch 4 - Loss: 0.0404722106481853, Test Loss Unfiltered: 0.30034104434991743, Test Loss: 0.039505767094864766\n",
      "Epoch 4 - Loss: 0.04083358309367346, Test Loss Unfiltered: 0.30034104434991743, Test Loss: 0.039505767094864766\n",
      "Epoch 4 - Loss: 0.04092586639033303, Test Loss Unfiltered: 0.30034104434991743, Test Loss: 0.039505767094864766\n",
      "Epoch 4 - Loss: 0.04052666393307117, Test Loss Unfiltered: 0.30034104434991743, Test Loss: 0.039505767094864766\n",
      "Epoch 4 - Loss: 0.0401830000880895, Test Loss Unfiltered: 0.30034104434991743, Test Loss: 0.039505767094864766\n",
      "Epoch 4 - Loss: 0.0410668655545822, Test Loss Unfiltered: 0.3015515797891957, Test Loss: 0.039284773226646724\n",
      "Epoch 4 - Loss: 0.04009579897818723, Test Loss Unfiltered: 0.3015515797891957, Test Loss: 0.039284773226646724\n",
      "Epoch 4 - Loss: 0.040192512451800104, Test Loss Unfiltered: 0.3015515797891957, Test Loss: 0.039284773226646724\n",
      "Epoch 4 - Loss: 0.03960706288450252, Test Loss Unfiltered: 0.3015515797891957, Test Loss: 0.039284773226646724\n",
      "Epoch 4 - Loss: 0.04020092846542923, Test Loss Unfiltered: 0.3015515797891957, Test Loss: 0.039284773226646724\n",
      "Epoch 4 - Loss: 0.040194540992059914, Test Loss Unfiltered: 0.30062065462754284, Test Loss: 0.03908288670616787\n",
      "Epoch 4 - Loss: 0.0398594411240648, Test Loss Unfiltered: 0.30062065462754284, Test Loss: 0.03908288670616787\n",
      "Epoch 4 - Loss: 0.04029858547594471, Test Loss Unfiltered: 0.30062065462754284, Test Loss: 0.03908288670616787\n",
      "Epoch 4 - Loss: 0.039795665536399766, Test Loss Unfiltered: 0.30062065462754284, Test Loss: 0.03908288670616787\n",
      "Epoch 4 - Loss: 0.04018372905556336, Test Loss Unfiltered: 0.30062065462754284, Test Loss: 0.03908288670616787\n",
      "Epoch 4 - Loss: 0.03908241920242019, Test Loss Unfiltered: 0.3020609740454975, Test Loss: 0.03813613925212662\n",
      "Epoch 4 - Loss: 0.039832227473583386, Test Loss Unfiltered: 0.3020609740454975, Test Loss: 0.03813613925212662\n",
      "Epoch 4 - Loss: 0.03915924005506536, Test Loss Unfiltered: 0.3020609740454975, Test Loss: 0.03813613925212662\n",
      "Epoch 4 - Loss: 0.04002960816572511, Test Loss Unfiltered: 0.3020609740454975, Test Loss: 0.03813613925212662\n",
      "Epoch 4 - Loss: 0.03938133666861846, Test Loss Unfiltered: 0.3020609740454975, Test Loss: 0.03813613925212662\n",
      "Epoch 5 - Loss: 0.038095985710059364, Test Loss Unfiltered: 0.30054841999726295, Test Loss: 0.03790187117025111\n",
      "Epoch 5 - Loss: 0.03839942369562847, Test Loss Unfiltered: 0.30054841999726295, Test Loss: 0.03790187117025111\n",
      "Epoch 5 - Loss: 0.0381555029534307, Test Loss Unfiltered: 0.30054841999726295, Test Loss: 0.03790187117025111\n",
      "Epoch 5 - Loss: 0.03804587075085057, Test Loss Unfiltered: 0.30054841999726295, Test Loss: 0.03790187117025111\n",
      "Epoch 5 - Loss: 0.03799813228346285, Test Loss Unfiltered: 0.30054841999726295, Test Loss: 0.03790187117025111\n",
      "Epoch 5 - Loss: 0.038549395375093824, Test Loss Unfiltered: 0.30071816233728954, Test Loss: 0.03740203363977251\n",
      "Epoch 5 - Loss: 0.03823429304634653, Test Loss Unfiltered: 0.30071816233728954, Test Loss: 0.03740203363977251\n",
      "Epoch 5 - Loss: 0.037859195473598124, Test Loss Unfiltered: 0.30071816233728954, Test Loss: 0.03740203363977251\n",
      "Epoch 5 - Loss: 0.038579777951086594, Test Loss Unfiltered: 0.30071816233728954, Test Loss: 0.03740203363977251\n",
      "Epoch 5 - Loss: 0.037537849646060314, Test Loss Unfiltered: 0.30071816233728954, Test Loss: 0.03740203363977251\n",
      "Epoch 5 - Loss: 0.037882740133152626, Test Loss Unfiltered: 0.3007317388844866, Test Loss: 0.0372126049985146\n",
      "Epoch 5 - Loss: 0.03782678976043863, Test Loss Unfiltered: 0.3007317388844866, Test Loss: 0.0372126049985146\n",
      "Epoch 5 - Loss: 0.03768133215444963, Test Loss Unfiltered: 0.3007317388844866, Test Loss: 0.0372126049985146\n",
      "Epoch 5 - Loss: 0.03808962405954874, Test Loss Unfiltered: 0.3007317388844866, Test Loss: 0.0372126049985146\n",
      "Epoch 5 - Loss: 0.03778040553728193, Test Loss Unfiltered: 0.3007317388844866, Test Loss: 0.0372126049985146\n",
      "Epoch 5 - Loss: 0.03740631711982652, Test Loss Unfiltered: 0.3001617363975131, Test Loss: 0.037040121664645494\n",
      "Epoch 5 - Loss: 0.03787285512209191, Test Loss Unfiltered: 0.3001617363975131, Test Loss: 0.037040121664645494\n",
      "Epoch 5 - Loss: 0.037855981505299216, Test Loss Unfiltered: 0.3001617363975131, Test Loss: 0.037040121664645494\n",
      "Epoch 5 - Loss: 0.03762214923759492, Test Loss Unfiltered: 0.3001617363975131, Test Loss: 0.037040121664645494\n",
      "Epoch 5 - Loss: 0.03765666517512305, Test Loss Unfiltered: 0.3001617363975131, Test Loss: 0.037040121664645494\n",
      "Epoch 5 - Loss: 0.03733620768863246, Test Loss Unfiltered: 0.29993335069954574, Test Loss: 0.03681484805353833\n",
      "Epoch 5 - Loss: 0.03735208047229579, Test Loss Unfiltered: 0.29993335069954574, Test Loss: 0.03681484805353833\n",
      "Epoch 5 - Loss: 0.03754369370566464, Test Loss Unfiltered: 0.29993335069954574, Test Loss: 0.03681484805353833\n",
      "Epoch 5 - Loss: 0.037036366217876204, Test Loss Unfiltered: 0.29993335069954574, Test Loss: 0.03681484805353833\n",
      "Epoch 5 - Loss: 0.0367663389362087, Test Loss Unfiltered: 0.29993335069954574, Test Loss: 0.03681484805353833\n",
      "Epoch 6 - Loss: 0.0359392996368336, Test Loss Unfiltered: 0.3008559536862994, Test Loss: 0.03671866319272213\n",
      "Epoch 6 - Loss: 0.03604986312942052, Test Loss Unfiltered: 0.3008559536862994, Test Loss: 0.03671866319272213\n",
      "Epoch 6 - Loss: 0.03610243826148423, Test Loss Unfiltered: 0.3008559536862994, Test Loss: 0.03671866319272213\n",
      "Epoch 6 - Loss: 0.036639729749521954, Test Loss Unfiltered: 0.3008559536862994, Test Loss: 0.03671866319272213\n",
      "Epoch 6 - Loss: 0.03657442306758753, Test Loss Unfiltered: 0.3008559536862994, Test Loss: 0.03671866319272213\n",
      "Epoch 6 - Loss: 0.036132793459749485, Test Loss Unfiltered: 0.29983058577323857, Test Loss: 0.03611356204554756\n",
      "Epoch 6 - Loss: 0.03606268932821318, Test Loss Unfiltered: 0.29983058577323857, Test Loss: 0.03611356204554756\n",
      "Epoch 6 - Loss: 0.03563274812023397, Test Loss Unfiltered: 0.29983058577323857, Test Loss: 0.03611356204554756\n",
      "Epoch 6 - Loss: 0.0357395786776427, Test Loss Unfiltered: 0.29983058577323857, Test Loss: 0.03611356204554756\n",
      "Epoch 6 - Loss: 0.03591299353855197, Test Loss Unfiltered: 0.29983058577323857, Test Loss: 0.03611356204554756\n",
      "Epoch 6 - Loss: 0.036156296341473236, Test Loss Unfiltered: 0.3014675136023453, Test Loss: 0.035863962261446655\n",
      "Epoch 6 - Loss: 0.03622018796043713, Test Loss Unfiltered: 0.3014675136023453, Test Loss: 0.035863962261446655\n",
      "Epoch 6 - Loss: 0.03615680447152001, Test Loss Unfiltered: 0.3014675136023453, Test Loss: 0.035863962261446655\n",
      "Epoch 6 - Loss: 0.03622911927332609, Test Loss Unfiltered: 0.3014675136023453, Test Loss: 0.035863962261446655\n",
      "Epoch 6 - Loss: 0.03582916860043949, Test Loss Unfiltered: 0.3014675136023453, Test Loss: 0.035863962261446655\n",
      "Epoch 6 - Loss: 0.03631075979653487, Test Loss Unfiltered: 0.29932147024204075, Test Loss: 0.03579773034207774\n",
      "Epoch 6 - Loss: 0.03540986664971924, Test Loss Unfiltered: 0.29932147024204075, Test Loss: 0.03579773034207774\n",
      "Epoch 6 - Loss: 0.03572865720930697, Test Loss Unfiltered: 0.29932147024204075, Test Loss: 0.03579773034207774\n",
      "Epoch 6 - Loss: 0.03568863007695701, Test Loss Unfiltered: 0.29932147024204075, Test Loss: 0.03579773034207774\n",
      "Epoch 6 - Loss: 0.03582643619497252, Test Loss Unfiltered: 0.29932147024204075, Test Loss: 0.03579773034207774\n",
      "Epoch 6 - Loss: 0.03562916372651478, Test Loss Unfiltered: 0.29998877418716646, Test Loss: 0.03484972390136307\n",
      "Epoch 6 - Loss: 0.035887860274427155, Test Loss Unfiltered: 0.29998877418716646, Test Loss: 0.03484972390136307\n",
      "Epoch 6 - Loss: 0.03558840142760051, Test Loss Unfiltered: 0.29998877418716646, Test Loss: 0.03484972390136307\n",
      "Epoch 6 - Loss: 0.035596154974162436, Test Loss Unfiltered: 0.29998877418716646, Test Loss: 0.03484972390136307\n",
      "Epoch 6 - Loss: 0.03533678791134791, Test Loss Unfiltered: 0.29998877418716646, Test Loss: 0.03484972390136307\n",
      "Epoch 7 - Loss: 0.03480799673852187, Test Loss Unfiltered: 0.3009675595083206, Test Loss: 0.035064580832766576\n",
      "Epoch 7 - Loss: 0.034632794235723116, Test Loss Unfiltered: 0.3009675595083206, Test Loss: 0.035064580832766576\n",
      "Epoch 7 - Loss: 0.03444303183509969, Test Loss Unfiltered: 0.3009675595083206, Test Loss: 0.035064580832766576\n",
      "Epoch 7 - Loss: 0.034681163530080085, Test Loss Unfiltered: 0.3009675595083206, Test Loss: 0.035064580832766576\n",
      "Epoch 7 - Loss: 0.03432692025186706, Test Loss Unfiltered: 0.3009675595083206, Test Loss: 0.035064580832766576\n",
      "Epoch 7 - Loss: 0.03439089617704297, Test Loss Unfiltered: 0.3000370636654853, Test Loss: 0.03460359736044817\n",
      "Epoch 7 - Loss: 0.0341733692346218, Test Loss Unfiltered: 0.3000370636654853, Test Loss: 0.03460359736044817\n",
      "Epoch 7 - Loss: 0.034773793940715766, Test Loss Unfiltered: 0.3000370636654853, Test Loss: 0.03460359736044817\n",
      "Epoch 7 - Loss: 0.03440264796612233, Test Loss Unfiltered: 0.3000370636654853, Test Loss: 0.03460359736044817\n",
      "Epoch 7 - Loss: 0.03437293560766545, Test Loss Unfiltered: 0.3000370636654853, Test Loss: 0.03460359736044817\n",
      "Epoch 7 - Loss: 0.03434559530213103, Test Loss Unfiltered: 0.29983715662102833, Test Loss: 0.033897963462225116\n",
      "Epoch 7 - Loss: 0.03475100810329043, Test Loss Unfiltered: 0.29983715662102833, Test Loss: 0.033897963462225116\n",
      "Epoch 7 - Loss: 0.03408346007209162, Test Loss Unfiltered: 0.29983715662102833, Test Loss: 0.033897963462225116\n",
      "Epoch 7 - Loss: 0.034465490006190785, Test Loss Unfiltered: 0.29983715662102833, Test Loss: 0.033897963462225116\n",
      "Epoch 7 - Loss: 0.034944851365721896, Test Loss Unfiltered: 0.29983715662102833, Test Loss: 0.033897963462225116\n",
      "Epoch 7 - Loss: 0.034357205204115705, Test Loss Unfiltered: 0.29842159689220726, Test Loss: 0.03506709293869997\n",
      "Epoch 7 - Loss: 0.03443863481236421, Test Loss Unfiltered: 0.29842159689220726, Test Loss: 0.03506709293869997\n",
      "Epoch 7 - Loss: 0.034365369435133644, Test Loss Unfiltered: 0.29842159689220726, Test Loss: 0.03506709293869997\n",
      "Epoch 7 - Loss: 0.03442998277201611, Test Loss Unfiltered: 0.29842159689220726, Test Loss: 0.03506709293869997\n",
      "Epoch 7 - Loss: 0.03437151914686159, Test Loss Unfiltered: 0.29842159689220726, Test Loss: 0.03506709293869997\n",
      "Epoch 7 - Loss: 0.03454672353530603, Test Loss Unfiltered: 0.3000023712084986, Test Loss: 0.034385029877856924\n",
      "Epoch 7 - Loss: 0.034367662345378046, Test Loss Unfiltered: 0.3000023712084986, Test Loss: 0.034385029877856924\n",
      "Epoch 7 - Loss: 0.03391557860789286, Test Loss Unfiltered: 0.3000023712084986, Test Loss: 0.034385029877856924\n",
      "Epoch 7 - Loss: 0.03468367871370732, Test Loss Unfiltered: 0.3000023712084986, Test Loss: 0.034385029877856924\n",
      "Epoch 7 - Loss: 0.03427447800126402, Test Loss Unfiltered: 0.3000023712084986, Test Loss: 0.034385029877856924\n",
      "Epoch 8 - Loss: 0.033156840835361134, Test Loss Unfiltered: 0.2989693487649556, Test Loss: 0.034027096643265566\n",
      "Epoch 8 - Loss: 0.03320283596206254, Test Loss Unfiltered: 0.2989693487649556, Test Loss: 0.034027096643265566\n",
      "Epoch 8 - Loss: 0.03335086881294338, Test Loss Unfiltered: 0.2989693487649556, Test Loss: 0.034027096643265566\n",
      "Epoch 8 - Loss: 0.03286467769436769, Test Loss Unfiltered: 0.2989693487649556, Test Loss: 0.034027096643265566\n",
      "Epoch 8 - Loss: 0.03312520350841021, Test Loss Unfiltered: 0.2989693487649556, Test Loss: 0.034027096643265566\n",
      "Epoch 8 - Loss: 0.03328383612230935, Test Loss Unfiltered: 0.29886455815978646, Test Loss: 0.034407682261301024\n",
      "Epoch 8 - Loss: 0.0334073574949743, Test Loss Unfiltered: 0.29886455815978646, Test Loss: 0.034407682261301024\n",
      "Epoch 8 - Loss: 0.03332424136246367, Test Loss Unfiltered: 0.29886455815978646, Test Loss: 0.034407682261301024\n",
      "Epoch 8 - Loss: 0.03361336505429712, Test Loss Unfiltered: 0.29886455815978646, Test Loss: 0.034407682261301024\n",
      "Epoch 8 - Loss: 0.033327986834677394, Test Loss Unfiltered: 0.29886455815978646, Test Loss: 0.034407682261301024\n",
      "Epoch 8 - Loss: 0.03317037123057512, Test Loss Unfiltered: 0.29905166296265745, Test Loss: 0.03378782918354897\n",
      "Epoch 8 - Loss: 0.033103044933955335, Test Loss Unfiltered: 0.29905166296265745, Test Loss: 0.03378782918354897\n",
      "Epoch 8 - Loss: 0.03332749575911175, Test Loss Unfiltered: 0.29905166296265745, Test Loss: 0.03378782918354897\n",
      "Epoch 8 - Loss: 0.03297648622909818, Test Loss Unfiltered: 0.29905166296265745, Test Loss: 0.03378782918354897\n",
      "Epoch 8 - Loss: 0.033432835041686246, Test Loss Unfiltered: 0.29905166296265745, Test Loss: 0.03378782918354897\n",
      "Epoch 8 - Loss: 0.03309201694640351, Test Loss Unfiltered: 0.2989175381949282, Test Loss: 0.03407822178180088\n",
      "Epoch 8 - Loss: 0.033375844888567846, Test Loss Unfiltered: 0.2989175381949282, Test Loss: 0.03407822178180088\n",
      "Epoch 8 - Loss: 0.0332098203699855, Test Loss Unfiltered: 0.2989175381949282, Test Loss: 0.03407822178180088\n",
      "Epoch 8 - Loss: 0.03315261726369865, Test Loss Unfiltered: 0.2989175381949282, Test Loss: 0.03407822178180088\n",
      "Epoch 8 - Loss: 0.03360824980880171, Test Loss Unfiltered: 0.2989175381949282, Test Loss: 0.03407822178180088\n",
      "Epoch 8 - Loss: 0.03380763542650287, Test Loss Unfiltered: 0.2977248535128435, Test Loss: 0.03307076439476011\n",
      "Epoch 8 - Loss: 0.03346607348620532, Test Loss Unfiltered: 0.2977248535128435, Test Loss: 0.03307076439476011\n",
      "Epoch 8 - Loss: 0.032965016498807675, Test Loss Unfiltered: 0.2977248535128435, Test Loss: 0.03307076439476011\n",
      "Epoch 8 - Loss: 0.0329433008342152, Test Loss Unfiltered: 0.2977248535128435, Test Loss: 0.03307076439476011\n",
      "Epoch 8 - Loss: 0.033088708816391386, Test Loss Unfiltered: 0.2977248535128435, Test Loss: 0.03307076439476011\n",
      "Epoch 9 - Loss: 0.03201276662769694, Test Loss Unfiltered: 0.299467816501802, Test Loss: 0.033351108463984994\n",
      "Epoch 9 - Loss: 0.03184876973759425, Test Loss Unfiltered: 0.299467816501802, Test Loss: 0.033351108463984994\n",
      "Epoch 9 - Loss: 0.03208160503641357, Test Loss Unfiltered: 0.299467816501802, Test Loss: 0.033351108463984994\n",
      "Epoch 9 - Loss: 0.03250466761652203, Test Loss Unfiltered: 0.299467816501802, Test Loss: 0.033351108463984994\n",
      "Epoch 9 - Loss: 0.032306169084392475, Test Loss Unfiltered: 0.299467816501802, Test Loss: 0.033351108463984994\n",
      "Epoch 9 - Loss: 0.03221048589102516, Test Loss Unfiltered: 0.29891821863386775, Test Loss: 0.03335852735639223\n",
      "Epoch 9 - Loss: 0.03208365069301827, Test Loss Unfiltered: 0.29891821863386775, Test Loss: 0.03335852735639223\n",
      "Epoch 9 - Loss: 0.03233990522022144, Test Loss Unfiltered: 0.29891821863386775, Test Loss: 0.03335852735639223\n",
      "Epoch 9 - Loss: 0.0325637003463647, Test Loss Unfiltered: 0.29891821863386775, Test Loss: 0.03335852735639223\n",
      "Epoch 9 - Loss: 0.032240124718861625, Test Loss Unfiltered: 0.29891821863386775, Test Loss: 0.03335852735639223\n",
      "Epoch 9 - Loss: 0.03212941754163797, Test Loss Unfiltered: 0.2988157581629388, Test Loss: 0.03344439968956356\n",
      "Epoch 9 - Loss: 0.032582410032765866, Test Loss Unfiltered: 0.2988157581629388, Test Loss: 0.03344439968956356\n",
      "Epoch 9 - Loss: 0.03234940515004471, Test Loss Unfiltered: 0.2988157581629388, Test Loss: 0.03344439968956356\n",
      "Epoch 9 - Loss: 0.03245250802111591, Test Loss Unfiltered: 0.2988157581629388, Test Loss: 0.03344439968956356\n",
      "Epoch 9 - Loss: 0.03255321191552264, Test Loss Unfiltered: 0.2988157581629388, Test Loss: 0.03344439968956356\n",
      "Epoch 9 - Loss: 0.0323380255776977, Test Loss Unfiltered: 0.29975244211500834, Test Loss: 0.03288636540424952\n",
      "Epoch 9 - Loss: 0.031893990493872156, Test Loss Unfiltered: 0.29975244211500834, Test Loss: 0.03288636540424952\n",
      "Epoch 9 - Loss: 0.032193180194009775, Test Loss Unfiltered: 0.29975244211500834, Test Loss: 0.03288636540424952\n",
      "Epoch 9 - Loss: 0.03224170624879282, Test Loss Unfiltered: 0.29975244211500834, Test Loss: 0.03288636540424952\n",
      "Epoch 9 - Loss: 0.03229009869542662, Test Loss Unfiltered: 0.29975244211500834, Test Loss: 0.03288636540424952\n",
      "Epoch 9 - Loss: 0.032253023100642646, Test Loss Unfiltered: 0.2994696131652357, Test Loss: 0.03344011811036495\n",
      "Epoch 9 - Loss: 0.032370845529121006, Test Loss Unfiltered: 0.2994696131652357, Test Loss: 0.03344011811036495\n",
      "Epoch 9 - Loss: 0.032369979449307695, Test Loss Unfiltered: 0.2994696131652357, Test Loss: 0.03344011811036495\n",
      "Epoch 9 - Loss: 0.03202445484614768, Test Loss Unfiltered: 0.2994696131652357, Test Loss: 0.03344011811036495\n",
      "Epoch 9 - Loss: 0.031928389335596045, Test Loss Unfiltered: 0.2994696131652357, Test Loss: 0.03344011811036495\n",
      "Epoch 10 - Loss: 0.031046600302348338, Test Loss Unfiltered: 0.2989259945504787, Test Loss: 0.03282508834469532\n",
      "Epoch 10 - Loss: 0.03104389654579464, Test Loss Unfiltered: 0.2989259945504787, Test Loss: 0.03282508834469532\n",
      "Epoch 10 - Loss: 0.031078791697474496, Test Loss Unfiltered: 0.2989259945504787, Test Loss: 0.03282508834469532\n",
      "Epoch 10 - Loss: 0.03130893163403784, Test Loss Unfiltered: 0.2989259945504787, Test Loss: 0.03282508834469532\n",
      "Epoch 10 - Loss: 0.031097836228755817, Test Loss Unfiltered: 0.2989259945504787, Test Loss: 0.03282508834469532\n",
      "Epoch 10 - Loss: 0.030977919632980626, Test Loss Unfiltered: 0.29932078916674015, Test Loss: 0.03217015218863879\n",
      "Epoch 10 - Loss: 0.030813645014399954, Test Loss Unfiltered: 0.29932078916674015, Test Loss: 0.03217015218863879\n",
      "Epoch 10 - Loss: 0.03141767763043453, Test Loss Unfiltered: 0.29932078916674015, Test Loss: 0.03217015218863879\n",
      "Epoch 10 - Loss: 0.0313149412498083, Test Loss Unfiltered: 0.29932078916674015, Test Loss: 0.03217015218863879\n",
      "Epoch 10 - Loss: 0.031740551599066795, Test Loss Unfiltered: 0.29932078916674015, Test Loss: 0.03217015218863879\n",
      "Epoch 10 - Loss: 0.031085772701257567, Test Loss Unfiltered: 0.2981157689645098, Test Loss: 0.032869414727228236\n",
      "Epoch 10 - Loss: 0.03125919790960423, Test Loss Unfiltered: 0.2981157689645098, Test Loss: 0.032869414727228236\n",
      "Epoch 10 - Loss: 0.0316072781642141, Test Loss Unfiltered: 0.2981157689645098, Test Loss: 0.032869414727228236\n",
      "Epoch 10 - Loss: 0.03117976223795702, Test Loss Unfiltered: 0.2981157689645098, Test Loss: 0.032869414727228236\n",
      "Epoch 10 - Loss: 0.03144594144375034, Test Loss Unfiltered: 0.2981157689645098, Test Loss: 0.032869414727228236\n",
      "Epoch 10 - Loss: 0.03170474349165705, Test Loss Unfiltered: 0.2994534040605095, Test Loss: 0.032411746926950376\n",
      "Epoch 10 - Loss: 0.0312853221873689, Test Loss Unfiltered: 0.2994534040605095, Test Loss: 0.032411746926950376\n",
      "Epoch 10 - Loss: 0.031657516250531044, Test Loss Unfiltered: 0.2994534040605095, Test Loss: 0.032411746926950376\n",
      "Epoch 10 - Loss: 0.03166120985365876, Test Loss Unfiltered: 0.2994534040605095, Test Loss: 0.032411746926950376\n",
      "Epoch 10 - Loss: 0.03143138616113656, Test Loss Unfiltered: 0.2994534040605095, Test Loss: 0.032411746926950376\n",
      "Epoch 10 - Loss: 0.03131743109008209, Test Loss Unfiltered: 0.2986925459041607, Test Loss: 0.03260543957177297\n",
      "Epoch 10 - Loss: 0.03130519511731333, Test Loss Unfiltered: 0.2986925459041607, Test Loss: 0.03260543957177297\n",
      "Epoch 10 - Loss: 0.03185105412874961, Test Loss Unfiltered: 0.2986925459041607, Test Loss: 0.03260543957177297\n",
      "Epoch 10 - Loss: 0.03196959365694918, Test Loss Unfiltered: 0.2986925459041607, Test Loss: 0.03260543957177297\n",
      "Epoch 10 - Loss: 0.03195771408952958, Test Loss Unfiltered: 0.2986925459041607, Test Loss: 0.03260543957177297\n",
      "Epoch 11 - Loss: 0.0300480920914495, Test Loss Unfiltered: 0.29795586244864286, Test Loss: 0.032240700318627864\n",
      "Epoch 11 - Loss: 0.030082890423503893, Test Loss Unfiltered: 0.29795586244864286, Test Loss: 0.032240700318627864\n",
      "Epoch 11 - Loss: 0.030123555037167935, Test Loss Unfiltered: 0.29795586244864286, Test Loss: 0.032240700318627864\n",
      "Epoch 11 - Loss: 0.030536780143774547, Test Loss Unfiltered: 0.29795586244864286, Test Loss: 0.032240700318627864\n",
      "Epoch 11 - Loss: 0.030502848788967158, Test Loss Unfiltered: 0.29795586244864286, Test Loss: 0.032240700318627864\n",
      "Epoch 11 - Loss: 0.02999770367621907, Test Loss Unfiltered: 0.29824281685896503, Test Loss: 0.0322581747490035\n",
      "Epoch 11 - Loss: 0.03046820749185189, Test Loss Unfiltered: 0.29824281685896503, Test Loss: 0.0322581747490035\n",
      "Epoch 11 - Loss: 0.03088660039030222, Test Loss Unfiltered: 0.29824281685896503, Test Loss: 0.0322581747490035\n",
      "Epoch 11 - Loss: 0.03032599081532521, Test Loss Unfiltered: 0.29824281685896503, Test Loss: 0.0322581747490035\n",
      "Epoch 11 - Loss: 0.03089261104153521, Test Loss Unfiltered: 0.29824281685896503, Test Loss: 0.0322581747490035\n",
      "Epoch 11 - Loss: 0.030673791375083283, Test Loss Unfiltered: 0.2984183901945402, Test Loss: 0.03227220193010789\n",
      "Epoch 11 - Loss: 0.030421413837053612, Test Loss Unfiltered: 0.2984183901945402, Test Loss: 0.03227220193010789\n",
      "Epoch 11 - Loss: 0.030832563447938287, Test Loss Unfiltered: 0.2984183901945402, Test Loss: 0.03227220193010789\n",
      "Epoch 11 - Loss: 0.030727898367962726, Test Loss Unfiltered: 0.2984183901945402, Test Loss: 0.03227220193010789\n",
      "Epoch 11 - Loss: 0.030684768365993546, Test Loss Unfiltered: 0.2984183901945402, Test Loss: 0.03227220193010789\n",
      "Epoch 11 - Loss: 0.030578126633547406, Test Loss Unfiltered: 0.2990210146832623, Test Loss: 0.0317371026918755\n",
      "Epoch 11 - Loss: 0.030344322013495954, Test Loss Unfiltered: 0.2990210146832623, Test Loss: 0.0317371026918755\n",
      "Epoch 11 - Loss: 0.031060234439168468, Test Loss Unfiltered: 0.2990210146832623, Test Loss: 0.0317371026918755\n",
      "Epoch 11 - Loss: 0.03067752338190502, Test Loss Unfiltered: 0.2990210146832623, Test Loss: 0.0317371026918755\n",
      "Epoch 11 - Loss: 0.030920849431209006, Test Loss Unfiltered: 0.2990210146832623, Test Loss: 0.0317371026918755\n",
      "Epoch 11 - Loss: 0.030640774510744758, Test Loss Unfiltered: 0.29892568082096127, Test Loss: 0.03235003583450184\n",
      "Epoch 11 - Loss: 0.030717944010056116, Test Loss Unfiltered: 0.29892568082096127, Test Loss: 0.03235003583450184\n",
      "Epoch 11 - Loss: 0.03090365267240495, Test Loss Unfiltered: 0.29892568082096127, Test Loss: 0.03235003583450184\n",
      "Epoch 11 - Loss: 0.031149654645088197, Test Loss Unfiltered: 0.29892568082096127, Test Loss: 0.03235003583450184\n",
      "Epoch 11 - Loss: 0.031010229819869683, Test Loss Unfiltered: 0.29892568082096127, Test Loss: 0.03235003583450184\n",
      "Epoch 12 - Loss: 0.029230536672354528, Test Loss Unfiltered: 0.29850445199307307, Test Loss: 0.03191395978286517\n",
      "Epoch 12 - Loss: 0.02958012155668749, Test Loss Unfiltered: 0.29850445199307307, Test Loss: 0.03191395978286517\n",
      "Epoch 12 - Loss: 0.0294231863367057, Test Loss Unfiltered: 0.29850445199307307, Test Loss: 0.03191395978286517\n",
      "Epoch 12 - Loss: 0.029441619479946002, Test Loss Unfiltered: 0.29850445199307307, Test Loss: 0.03191395978286517\n",
      "Epoch 12 - Loss: 0.029878251018668922, Test Loss Unfiltered: 0.29850445199307307, Test Loss: 0.03191395978286517\n",
      "Epoch 12 - Loss: 0.029590708891034257, Test Loss Unfiltered: 0.2990483305289103, Test Loss: 0.032218349798319605\n",
      "Epoch 12 - Loss: 0.02985583303546675, Test Loss Unfiltered: 0.2990483305289103, Test Loss: 0.032218349798319605\n",
      "Epoch 12 - Loss: 0.02964072152242894, Test Loss Unfiltered: 0.2990483305289103, Test Loss: 0.032218349798319605\n",
      "Epoch 12 - Loss: 0.02949314698377874, Test Loss Unfiltered: 0.2990483305289103, Test Loss: 0.032218349798319605\n",
      "Epoch 12 - Loss: 0.03011736941331375, Test Loss Unfiltered: 0.2990483305289103, Test Loss: 0.032218349798319605\n",
      "Epoch 12 - Loss: 0.030023841894413848, Test Loss Unfiltered: 0.2981871997564762, Test Loss: 0.03155492777772018\n",
      "Epoch 12 - Loss: 0.030225845527559164, Test Loss Unfiltered: 0.2981871997564762, Test Loss: 0.03155492777772018\n",
      "Epoch 12 - Loss: 0.029823574328573917, Test Loss Unfiltered: 0.2981871997564762, Test Loss: 0.03155492777772018\n",
      "Epoch 12 - Loss: 0.029863818854594396, Test Loss Unfiltered: 0.2981871997564762, Test Loss: 0.03155492777772018\n",
      "Epoch 12 - Loss: 0.030010788623100255, Test Loss Unfiltered: 0.2981871997564762, Test Loss: 0.03155492777772018\n",
      "Epoch 12 - Loss: 0.030194712204072063, Test Loss Unfiltered: 0.2997753782157815, Test Loss: 0.03165052701808228\n",
      "Epoch 12 - Loss: 0.02960109784476288, Test Loss Unfiltered: 0.2997753782157815, Test Loss: 0.03165052701808228\n",
      "Epoch 12 - Loss: 0.030094836326478407, Test Loss Unfiltered: 0.2997753782157815, Test Loss: 0.03165052701808228\n",
      "Epoch 12 - Loss: 0.030152341534016695, Test Loss Unfiltered: 0.2997753782157815, Test Loss: 0.03165052701808228\n",
      "Epoch 12 - Loss: 0.030169413144827604, Test Loss Unfiltered: 0.2997753782157815, Test Loss: 0.03165052701808228\n",
      "Epoch 12 - Loss: 0.030292845030040903, Test Loss Unfiltered: 0.29738770084380906, Test Loss: 0.03195169661676496\n",
      "Epoch 12 - Loss: 0.03028393644668312, Test Loss Unfiltered: 0.29738770084380906, Test Loss: 0.03195169661676496\n",
      "Epoch 12 - Loss: 0.030029213237057772, Test Loss Unfiltered: 0.29738770084380906, Test Loss: 0.03195169661676496\n",
      "Epoch 12 - Loss: 0.030290831254139016, Test Loss Unfiltered: 0.29738770084380906, Test Loss: 0.03195169661676496\n",
      "Epoch 12 - Loss: 0.03024255601025842, Test Loss Unfiltered: 0.29738770084380906, Test Loss: 0.03195169661676496\n",
      "Epoch 13 - Loss: 0.028689834080499, Test Loss Unfiltered: 0.2986683603247242, Test Loss: 0.03151845624540431\n",
      "Epoch 13 - Loss: 0.02851897451141915, Test Loss Unfiltered: 0.2986683603247242, Test Loss: 0.03151845624540431\n",
      "Epoch 13 - Loss: 0.029090131964721846, Test Loss Unfiltered: 0.2986683603247242, Test Loss: 0.03151845624540431\n",
      "Epoch 13 - Loss: 0.028832283582022927, Test Loss Unfiltered: 0.2986683603247242, Test Loss: 0.03151845624540431\n",
      "Epoch 13 - Loss: 0.029037790214988018, Test Loss Unfiltered: 0.2986683603247242, Test Loss: 0.03151845624540431\n",
      "Epoch 13 - Loss: 0.029274411396535308, Test Loss Unfiltered: 0.2986501143322357, Test Loss: 0.0313330288376027\n",
      "Epoch 13 - Loss: 0.02920595501596093, Test Loss Unfiltered: 0.2986501143322357, Test Loss: 0.0313330288376027\n",
      "Epoch 13 - Loss: 0.028930789462620413, Test Loss Unfiltered: 0.2986501143322357, Test Loss: 0.0313330288376027\n",
      "Epoch 13 - Loss: 0.02973294485745418, Test Loss Unfiltered: 0.2986501143322357, Test Loss: 0.0313330288376027\n",
      "Epoch 13 - Loss: 0.029235347939750224, Test Loss Unfiltered: 0.2986501143322357, Test Loss: 0.0313330288376027\n",
      "Epoch 13 - Loss: 0.028814201421628494, Test Loss Unfiltered: 0.29916632881427363, Test Loss: 0.031254519359913184\n",
      "Epoch 13 - Loss: 0.02897984441392395, Test Loss Unfiltered: 0.29916632881427363, Test Loss: 0.031254519359913184\n",
      "Epoch 13 - Loss: 0.02932705432924579, Test Loss Unfiltered: 0.29916632881427363, Test Loss: 0.031254519359913184\n",
      "Epoch 13 - Loss: 0.029684805601658804, Test Loss Unfiltered: 0.29916632881427363, Test Loss: 0.031254519359913184\n",
      "Epoch 13 - Loss: 0.029391121474345742, Test Loss Unfiltered: 0.29916632881427363, Test Loss: 0.031254519359913184\n",
      "Epoch 13 - Loss: 0.02915498809858358, Test Loss Unfiltered: 0.29923903785803135, Test Loss: 0.03151019671564148\n",
      "Epoch 13 - Loss: 0.029696612157136624, Test Loss Unfiltered: 0.29923903785803135, Test Loss: 0.03151019671564148\n",
      "Epoch 13 - Loss: 0.029271439534858005, Test Loss Unfiltered: 0.29923903785803135, Test Loss: 0.03151019671564148\n",
      "Epoch 13 - Loss: 0.029544031162096047, Test Loss Unfiltered: 0.29923903785803135, Test Loss: 0.03151019671564148\n",
      "Epoch 13 - Loss: 0.029741137916921834, Test Loss Unfiltered: 0.29923903785803135, Test Loss: 0.03151019671564148\n",
      "Epoch 13 - Loss: 0.029399789882187426, Test Loss Unfiltered: 0.29872156141632883, Test Loss: 0.03104444545900172\n",
      "Epoch 13 - Loss: 0.029226070971520277, Test Loss Unfiltered: 0.29872156141632883, Test Loss: 0.03104444545900172\n",
      "Epoch 13 - Loss: 0.029501235683194554, Test Loss Unfiltered: 0.29872156141632883, Test Loss: 0.03104444545900172\n",
      "Epoch 13 - Loss: 0.029673630840962067, Test Loss Unfiltered: 0.29872156141632883, Test Loss: 0.03104444545900172\n",
      "Epoch 13 - Loss: 0.02959369628275798, Test Loss Unfiltered: 0.29872156141632883, Test Loss: 0.03104444545900172\n",
      "Epoch 14 - Loss: 0.028278536397722657, Test Loss Unfiltered: 0.29882344278151557, Test Loss: 0.030857805367384937\n",
      "Epoch 14 - Loss: 0.02826810356825532, Test Loss Unfiltered: 0.29882344278151557, Test Loss: 0.030857805367384937\n",
      "Epoch 14 - Loss: 0.02847756839177256, Test Loss Unfiltered: 0.29882344278151557, Test Loss: 0.030857805367384937\n",
      "Epoch 14 - Loss: 0.02832931606875278, Test Loss Unfiltered: 0.29882344278151557, Test Loss: 0.030857805367384937\n",
      "Epoch 14 - Loss: 0.02845074131273963, Test Loss Unfiltered: 0.29882344278151557, Test Loss: 0.030857805367384937\n",
      "Epoch 14 - Loss: 0.02828354897541487, Test Loss Unfiltered: 0.29863599482245035, Test Loss: 0.03151292166810208\n",
      "Epoch 14 - Loss: 0.028733220115549112, Test Loss Unfiltered: 0.29863599482245035, Test Loss: 0.03151292166810208\n",
      "Epoch 14 - Loss: 0.02859750130256449, Test Loss Unfiltered: 0.29863599482245035, Test Loss: 0.03151292166810208\n",
      "Epoch 14 - Loss: 0.028612776670845233, Test Loss Unfiltered: 0.29863599482245035, Test Loss: 0.03151292166810208\n",
      "Epoch 14 - Loss: 0.02877297143660726, Test Loss Unfiltered: 0.29863599482245035, Test Loss: 0.03151292166810208\n",
      "Epoch 14 - Loss: 0.028847315283734427, Test Loss Unfiltered: 0.2993377576260096, Test Loss: 0.030896932479988388\n",
      "Epoch 14 - Loss: 0.02886166148662031, Test Loss Unfiltered: 0.2993377576260096, Test Loss: 0.030896932479988388\n",
      "Epoch 14 - Loss: 0.02920950527014256, Test Loss Unfiltered: 0.2993377576260096, Test Loss: 0.030896932479988388\n",
      "Epoch 14 - Loss: 0.028723990297230707, Test Loss Unfiltered: 0.2993377576260096, Test Loss: 0.030896932479988388\n",
      "Epoch 14 - Loss: 0.0288841016183253, Test Loss Unfiltered: 0.2993377576260096, Test Loss: 0.030896932479988388\n",
      "Epoch 14 - Loss: 0.028782642361692673, Test Loss Unfiltered: 0.29875856318718075, Test Loss: 0.03113011629898712\n",
      "Epoch 14 - Loss: 0.028633373759000116, Test Loss Unfiltered: 0.29875856318718075, Test Loss: 0.03113011629898712\n",
      "Epoch 14 - Loss: 0.029355948229720784, Test Loss Unfiltered: 0.29875856318718075, Test Loss: 0.03113011629898712\n",
      "Epoch 14 - Loss: 0.028790125764817476, Test Loss Unfiltered: 0.29875856318718075, Test Loss: 0.03113011629898712\n",
      "Epoch 14 - Loss: 0.02874634788356399, Test Loss Unfiltered: 0.29875856318718075, Test Loss: 0.03113011629898712\n",
      "Epoch 14 - Loss: 0.02887716237107209, Test Loss Unfiltered: 0.2989332246716283, Test Loss: 0.030786459123263228\n",
      "Epoch 14 - Loss: 0.028673466423756157, Test Loss Unfiltered: 0.2989332246716283, Test Loss: 0.030786459123263228\n",
      "Epoch 14 - Loss: 0.029039933224287155, Test Loss Unfiltered: 0.2989332246716283, Test Loss: 0.030786459123263228\n",
      "Epoch 14 - Loss: 0.029019597125889328, Test Loss Unfiltered: 0.2989332246716283, Test Loss: 0.030786459123263228\n",
      "Epoch 14 - Loss: 0.028504311873280373, Test Loss Unfiltered: 0.2989332246716283, Test Loss: 0.030786459123263228\n",
      "Epoch 15 - Loss: 0.027439572583492926, Test Loss Unfiltered: 0.29825988145886656, Test Loss: 0.030788180927181552\n",
      "Epoch 15 - Loss: 0.027784513922666714, Test Loss Unfiltered: 0.29825988145886656, Test Loss: 0.030788180927181552\n",
      "Epoch 15 - Loss: 0.02781668588230002, Test Loss Unfiltered: 0.29825988145886656, Test Loss: 0.030788180927181552\n",
      "Epoch 15 - Loss: 0.027583354142635165, Test Loss Unfiltered: 0.29825988145886656, Test Loss: 0.030788180927181552\n",
      "Epoch 15 - Loss: 0.028408418000281453, Test Loss Unfiltered: 0.29825988145886656, Test Loss: 0.030788180927181552\n",
      "Epoch 15 - Loss: 0.02794630156016303, Test Loss Unfiltered: 0.2988606615127609, Test Loss: 0.03082431566820849\n",
      "Epoch 15 - Loss: 0.028511267658595112, Test Loss Unfiltered: 0.2988606615127609, Test Loss: 0.03082431566820849\n",
      "Epoch 15 - Loss: 0.02824444343888984, Test Loss Unfiltered: 0.2988606615127609, Test Loss: 0.03082431566820849\n",
      "Epoch 15 - Loss: 0.02808900418130385, Test Loss Unfiltered: 0.2988606615127609, Test Loss: 0.03082431566820849\n",
      "Epoch 15 - Loss: 0.02792789301633856, Test Loss Unfiltered: 0.2988606615127609, Test Loss: 0.03082431566820849\n",
      "Epoch 15 - Loss: 0.02794993945920252, Test Loss Unfiltered: 0.2984290058937643, Test Loss: 0.030773494633530917\n",
      "Epoch 15 - Loss: 0.027848748920935005, Test Loss Unfiltered: 0.2984290058937643, Test Loss: 0.030773494633530917\n",
      "Epoch 15 - Loss: 0.028503714766882352, Test Loss Unfiltered: 0.2984290058937643, Test Loss: 0.030773494633530917\n",
      "Epoch 15 - Loss: 0.02837397511424328, Test Loss Unfiltered: 0.2984290058937643, Test Loss: 0.030773494633530917\n",
      "Epoch 15 - Loss: 0.028342016243233955, Test Loss Unfiltered: 0.2984290058937643, Test Loss: 0.030773494633530917\n",
      "Epoch 15 - Loss: 0.028083846727936377, Test Loss Unfiltered: 0.29940509885767397, Test Loss: 0.030751152904017764\n",
      "Epoch 15 - Loss: 0.028269498470603713, Test Loss Unfiltered: 0.29940509885767397, Test Loss: 0.030751152904017764\n",
      "Epoch 15 - Loss: 0.028558959183169818, Test Loss Unfiltered: 0.29940509885767397, Test Loss: 0.030751152904017764\n",
      "Epoch 15 - Loss: 0.02853560606206728, Test Loss Unfiltered: 0.29940509885767397, Test Loss: 0.030751152904017764\n",
      "Epoch 15 - Loss: 0.02831120481928498, Test Loss Unfiltered: 0.29940509885767397, Test Loss: 0.030751152904017764\n",
      "Epoch 15 - Loss: 0.028259759638765265, Test Loss Unfiltered: 0.2986672441998362, Test Loss: 0.03100226082975648\n",
      "Epoch 15 - Loss: 0.028267635194785923, Test Loss Unfiltered: 0.2986672441998362, Test Loss: 0.03100226082975648\n",
      "Epoch 15 - Loss: 0.02811576545614575, Test Loss Unfiltered: 0.2986672441998362, Test Loss: 0.03100226082975648\n",
      "Epoch 15 - Loss: 0.028467549242734536, Test Loss Unfiltered: 0.2986672441998362, Test Loss: 0.03100226082975648\n",
      "Epoch 15 - Loss: 0.028806152267397984, Test Loss Unfiltered: 0.2986672441998362, Test Loss: 0.03100226082975648\n",
      "Epoch 16 - Loss: 0.02721307356651796, Test Loss Unfiltered: 0.298815354590548, Test Loss: 0.03065266248895657\n",
      "Epoch 16 - Loss: 0.027003847516086876, Test Loss Unfiltered: 0.298815354590548, Test Loss: 0.03065266248895657\n",
      "Epoch 16 - Loss: 0.027071610146597282, Test Loss Unfiltered: 0.298815354590548, Test Loss: 0.03065266248895657\n",
      "Epoch 16 - Loss: 0.027804229982426737, Test Loss Unfiltered: 0.298815354590548, Test Loss: 0.03065266248895657\n",
      "Epoch 16 - Loss: 0.027216991970578256, Test Loss Unfiltered: 0.298815354590548, Test Loss: 0.03065266248895657\n",
      "Epoch 16 - Loss: 0.027257809128775595, Test Loss Unfiltered: 0.2984118262210236, Test Loss: 0.031010345327435424\n",
      "Epoch 16 - Loss: 0.027519055870311022, Test Loss Unfiltered: 0.2984118262210236, Test Loss: 0.031010345327435424\n",
      "Epoch 16 - Loss: 0.02718029105740642, Test Loss Unfiltered: 0.2984118262210236, Test Loss: 0.031010345327435424\n",
      "Epoch 16 - Loss: 0.027583983052210426, Test Loss Unfiltered: 0.2984118262210236, Test Loss: 0.031010345327435424\n",
      "Epoch 16 - Loss: 0.027604572935814743, Test Loss Unfiltered: 0.2984118262210236, Test Loss: 0.031010345327435424\n",
      "Epoch 16 - Loss: 0.027884919731638744, Test Loss Unfiltered: 0.29877677457119534, Test Loss: 0.031246627320823277\n",
      "Epoch 16 - Loss: 0.02770329574879411, Test Loss Unfiltered: 0.29877677457119534, Test Loss: 0.031246627320823277\n",
      "Epoch 16 - Loss: 0.02799374120441851, Test Loss Unfiltered: 0.29877677457119534, Test Loss: 0.031246627320823277\n",
      "Epoch 16 - Loss: 0.027509351124512475, Test Loss Unfiltered: 0.29877677457119534, Test Loss: 0.031246627320823277\n",
      "Epoch 16 - Loss: 0.027784182317454182, Test Loss Unfiltered: 0.29877677457119534, Test Loss: 0.031246627320823277\n",
      "Epoch 16 - Loss: 0.027840756942785188, Test Loss Unfiltered: 0.2990077532020858, Test Loss: 0.030568746717305535\n",
      "Epoch 16 - Loss: 0.027823703451593167, Test Loss Unfiltered: 0.2990077532020858, Test Loss: 0.030568746717305535\n",
      "Epoch 16 - Loss: 0.02818548731774851, Test Loss Unfiltered: 0.2990077532020858, Test Loss: 0.030568746717305535\n",
      "Epoch 16 - Loss: 0.027976346812706845, Test Loss Unfiltered: 0.2990077532020858, Test Loss: 0.030568746717305535\n",
      "Epoch 16 - Loss: 0.02806365880419585, Test Loss Unfiltered: 0.2990077532020858, Test Loss: 0.030568746717305535\n",
      "Epoch 16 - Loss: 0.027789563303004864, Test Loss Unfiltered: 0.29853376971130163, Test Loss: 0.03073415359083541\n",
      "Epoch 16 - Loss: 0.028031197612788026, Test Loss Unfiltered: 0.29853376971130163, Test Loss: 0.03073415359083541\n",
      "Epoch 16 - Loss: 0.028272948972744984, Test Loss Unfiltered: 0.29853376971130163, Test Loss: 0.03073415359083541\n",
      "Epoch 16 - Loss: 0.02821677195438546, Test Loss Unfiltered: 0.29853376971130163, Test Loss: 0.03073415359083541\n",
      "Epoch 16 - Loss: 0.028118081804563214, Test Loss Unfiltered: 0.29853376971130163, Test Loss: 0.03073415359083541\n",
      "Epoch 17 - Loss: 0.02644291227227173, Test Loss Unfiltered: 0.29923665842310115, Test Loss: 0.030586292183972737\n",
      "Epoch 17 - Loss: 0.026732070525514816, Test Loss Unfiltered: 0.29923665842310115, Test Loss: 0.030586292183972737\n",
      "Epoch 17 - Loss: 0.02695642429271527, Test Loss Unfiltered: 0.29923665842310115, Test Loss: 0.030586292183972737\n",
      "Epoch 17 - Loss: 0.026763743115444293, Test Loss Unfiltered: 0.29923665842310115, Test Loss: 0.030586292183972737\n",
      "Epoch 17 - Loss: 0.02696474238384759, Test Loss Unfiltered: 0.29923665842310115, Test Loss: 0.030586292183972737\n",
      "Epoch 17 - Loss: 0.027150866252624348, Test Loss Unfiltered: 0.2995488353692977, Test Loss: 0.030899922308475138\n",
      "Epoch 17 - Loss: 0.027435431059134718, Test Loss Unfiltered: 0.2995488353692977, Test Loss: 0.030899922308475138\n",
      "Epoch 17 - Loss: 0.02701289579148143, Test Loss Unfiltered: 0.2995488353692977, Test Loss: 0.030899922308475138\n",
      "Epoch 17 - Loss: 0.027217399129408498, Test Loss Unfiltered: 0.2995488353692977, Test Loss: 0.030899922308475138\n",
      "Epoch 17 - Loss: 0.026722946095283077, Test Loss Unfiltered: 0.2995488353692977, Test Loss: 0.030899922308475138\n",
      "Epoch 17 - Loss: 0.027496355002892395, Test Loss Unfiltered: 0.2991151387374779, Test Loss: 0.030283381918465364\n",
      "Epoch 17 - Loss: 0.02729048500004967, Test Loss Unfiltered: 0.2991151387374779, Test Loss: 0.030283381918465364\n",
      "Epoch 17 - Loss: 0.027218503545539802, Test Loss Unfiltered: 0.2991151387374779, Test Loss: 0.030283381918465364\n",
      "Epoch 17 - Loss: 0.027693024046948005, Test Loss Unfiltered: 0.2991151387374779, Test Loss: 0.030283381918465364\n",
      "Epoch 17 - Loss: 0.02756353896192983, Test Loss Unfiltered: 0.2991151387374779, Test Loss: 0.030283381918465364\n",
      "Epoch 17 - Loss: 0.027262042172709094, Test Loss Unfiltered: 0.29934406443842654, Test Loss: 0.030569900059598747\n",
      "Epoch 17 - Loss: 0.026719620302282567, Test Loss Unfiltered: 0.29934406443842654, Test Loss: 0.030569900059598747\n",
      "Epoch 17 - Loss: 0.02735971844208828, Test Loss Unfiltered: 0.29934406443842654, Test Loss: 0.030569900059598747\n",
      "Epoch 17 - Loss: 0.02751931770790574, Test Loss Unfiltered: 0.29934406443842654, Test Loss: 0.030569900059598747\n",
      "Epoch 17 - Loss: 0.027551981565764154, Test Loss Unfiltered: 0.29934406443842654, Test Loss: 0.030569900059598747\n",
      "Epoch 17 - Loss: 0.027785138807944133, Test Loss Unfiltered: 0.29743555337940264, Test Loss: 0.03038861921372444\n",
      "Epoch 17 - Loss: 0.02749406373282797, Test Loss Unfiltered: 0.29743555337940264, Test Loss: 0.03038861921372444\n",
      "Epoch 17 - Loss: 0.027672924778281857, Test Loss Unfiltered: 0.29743555337940264, Test Loss: 0.03038861921372444\n",
      "Epoch 17 - Loss: 0.027345137943303868, Test Loss Unfiltered: 0.29743555337940264, Test Loss: 0.03038861921372444\n",
      "Epoch 17 - Loss: 0.02770446556158003, Test Loss Unfiltered: 0.29743555337940264, Test Loss: 0.03038861921372444\n",
      "Epoch 18 - Loss: 0.026128577507675763, Test Loss Unfiltered: 0.2994425025885812, Test Loss: 0.030642658506014473\n",
      "Epoch 18 - Loss: 0.02629657627553535, Test Loss Unfiltered: 0.2994425025885812, Test Loss: 0.030642658506014473\n",
      "Epoch 18 - Loss: 0.026478934849384232, Test Loss Unfiltered: 0.2994425025885812, Test Loss: 0.030642658506014473\n",
      "Epoch 18 - Loss: 0.02601695531902009, Test Loss Unfiltered: 0.2994425025885812, Test Loss: 0.030642658506014473\n",
      "Epoch 18 - Loss: 0.026872604814578323, Test Loss Unfiltered: 0.2994425025885812, Test Loss: 0.030642658506014473\n",
      "Epoch 18 - Loss: 0.026645036208102373, Test Loss Unfiltered: 0.29871036772049037, Test Loss: 0.030730462653895733\n",
      "Epoch 18 - Loss: 0.02694148400521333, Test Loss Unfiltered: 0.29871036772049037, Test Loss: 0.030730462653895733\n",
      "Epoch 18 - Loss: 0.026396066475419516, Test Loss Unfiltered: 0.29871036772049037, Test Loss: 0.030730462653895733\n",
      "Epoch 18 - Loss: 0.02671724200617947, Test Loss Unfiltered: 0.29871036772049037, Test Loss: 0.030730462653895733\n",
      "Epoch 18 - Loss: 0.026508934749007177, Test Loss Unfiltered: 0.29871036772049037, Test Loss: 0.030730462653895733\n",
      "Epoch 18 - Loss: 0.026774506136393723, Test Loss Unfiltered: 0.29923437956034427, Test Loss: 0.030323913572576883\n",
      "Epoch 18 - Loss: 0.026719313022208212, Test Loss Unfiltered: 0.29923437956034427, Test Loss: 0.030323913572576883\n",
      "Epoch 18 - Loss: 0.02691622991190336, Test Loss Unfiltered: 0.29923437956034427, Test Loss: 0.030323913572576883\n",
      "Epoch 18 - Loss: 0.026999840145612356, Test Loss Unfiltered: 0.29923437956034427, Test Loss: 0.030323913572576883\n",
      "Epoch 18 - Loss: 0.0270773478116861, Test Loss Unfiltered: 0.29923437956034427, Test Loss: 0.030323913572576883\n",
      "Epoch 18 - Loss: 0.026880008249498315, Test Loss Unfiltered: 0.29987452991553004, Test Loss: 0.030547338039512487\n",
      "Epoch 18 - Loss: 0.026891233757581394, Test Loss Unfiltered: 0.29987452991553004, Test Loss: 0.030547338039512487\n",
      "Epoch 18 - Loss: 0.027117646003256255, Test Loss Unfiltered: 0.29987452991553004, Test Loss: 0.030547338039512487\n",
      "Epoch 18 - Loss: 0.027124785580410492, Test Loss Unfiltered: 0.29987452991553004, Test Loss: 0.030547338039512487\n",
      "Epoch 18 - Loss: 0.02712333747470888, Test Loss Unfiltered: 0.29987452991553004, Test Loss: 0.030547338039512487\n",
      "Epoch 18 - Loss: 0.02714272210693655, Test Loss Unfiltered: 0.2993533737258992, Test Loss: 0.030408234471799942\n",
      "Epoch 18 - Loss: 0.027168082598390146, Test Loss Unfiltered: 0.2993533737258992, Test Loss: 0.030408234471799942\n",
      "Epoch 18 - Loss: 0.02700608148180816, Test Loss Unfiltered: 0.2993533737258992, Test Loss: 0.030408234471799942\n",
      "Epoch 18 - Loss: 0.027092572974766048, Test Loss Unfiltered: 0.2993533737258992, Test Loss: 0.030408234471799942\n",
      "Epoch 18 - Loss: 0.02725538992728271, Test Loss Unfiltered: 0.2993533737258992, Test Loss: 0.030408234471799942\n",
      "Epoch 19 - Loss: 0.025851975081911952, Test Loss Unfiltered: 0.29913083991964734, Test Loss: 0.030804567337048932\n",
      "Epoch 19 - Loss: 0.02630516779019042, Test Loss Unfiltered: 0.29913083991964734, Test Loss: 0.030804567337048932\n",
      "Epoch 19 - Loss: 0.025906568549939772, Test Loss Unfiltered: 0.29913083991964734, Test Loss: 0.030804567337048932\n",
      "Epoch 19 - Loss: 0.02600191768601104, Test Loss Unfiltered: 0.29913083991964734, Test Loss: 0.030804567337048932\n",
      "Epoch 19 - Loss: 0.02613871689768749, Test Loss Unfiltered: 0.29913083991964734, Test Loss: 0.030804567337048932\n",
      "Epoch 19 - Loss: 0.026067867075590476, Test Loss Unfiltered: 0.2986982030785068, Test Loss: 0.029881840102789426\n",
      "Epoch 19 - Loss: 0.026306645095509784, Test Loss Unfiltered: 0.2986982030785068, Test Loss: 0.029881840102789426\n",
      "Epoch 19 - Loss: 0.02641022356336596, Test Loss Unfiltered: 0.2986982030785068, Test Loss: 0.029881840102789426\n",
      "Epoch 19 - Loss: 0.02643015542435316, Test Loss Unfiltered: 0.2986982030785068, Test Loss: 0.029881840102789426\n",
      "Epoch 19 - Loss: 0.026357945016924865, Test Loss Unfiltered: 0.2986982030785068, Test Loss: 0.029881840102789426\n",
      "Epoch 19 - Loss: 0.0261482226871445, Test Loss Unfiltered: 0.29932723618028506, Test Loss: 0.030822284484082328\n",
      "Epoch 19 - Loss: 0.02633685972607933, Test Loss Unfiltered: 0.29932723618028506, Test Loss: 0.030822284484082328\n",
      "Epoch 19 - Loss: 0.02615296641353515, Test Loss Unfiltered: 0.29932723618028506, Test Loss: 0.030822284484082328\n",
      "Epoch 19 - Loss: 0.02638727146033977, Test Loss Unfiltered: 0.29932723618028506, Test Loss: 0.030822284484082328\n",
      "Epoch 19 - Loss: 0.02666872178480374, Test Loss Unfiltered: 0.29932723618028506, Test Loss: 0.030822284484082328\n",
      "Epoch 19 - Loss: 0.02662057711304821, Test Loss Unfiltered: 0.2988296390012987, Test Loss: 0.030723676932975896\n",
      "Epoch 19 - Loss: 0.026442722582372902, Test Loss Unfiltered: 0.2988296390012987, Test Loss: 0.030723676932975896\n",
      "Epoch 19 - Loss: 0.026758295372596844, Test Loss Unfiltered: 0.2988296390012987, Test Loss: 0.030723676932975896\n",
      "Epoch 19 - Loss: 0.026719229257858537, Test Loss Unfiltered: 0.2988296390012987, Test Loss: 0.030723676932975896\n",
      "Epoch 19 - Loss: 0.026922835066112327, Test Loss Unfiltered: 0.2988296390012987, Test Loss: 0.030723676932975896\n",
      "Epoch 19 - Loss: 0.026304141088449556, Test Loss Unfiltered: 0.2990594169673675, Test Loss: 0.030546229282647712\n",
      "Epoch 19 - Loss: 0.02648825321686699, Test Loss Unfiltered: 0.2990594169673675, Test Loss: 0.030546229282647712\n",
      "Epoch 19 - Loss: 0.026723925609129888, Test Loss Unfiltered: 0.2990594169673675, Test Loss: 0.030546229282647712\n",
      "Epoch 19 - Loss: 0.027168070001931402, Test Loss Unfiltered: 0.2990594169673675, Test Loss: 0.030546229282647712\n",
      "Epoch 19 - Loss: 0.027014003439393048, Test Loss Unfiltered: 0.2990594169673675, Test Loss: 0.030546229282647712\n",
      "Epoch 20 - Loss: 0.025554357511071924, Test Loss Unfiltered: 0.29839625769435124, Test Loss: 0.030124742784516823\n",
      "Epoch 20 - Loss: 0.0255854631786806, Test Loss Unfiltered: 0.29839625769435124, Test Loss: 0.030124742784516823\n",
      "Epoch 20 - Loss: 0.025799422877816395, Test Loss Unfiltered: 0.29839625769435124, Test Loss: 0.030124742784516823\n",
      "Epoch 20 - Loss: 0.026102900297671826, Test Loss Unfiltered: 0.29839625769435124, Test Loss: 0.030124742784516823\n",
      "Epoch 20 - Loss: 0.02612487831972079, Test Loss Unfiltered: 0.29839625769435124, Test Loss: 0.030124742784516823\n",
      "Epoch 20 - Loss: 0.02575371284697985, Test Loss Unfiltered: 0.29933677590562796, Test Loss: 0.03066158407060869\n",
      "Epoch 20 - Loss: 0.02581625252768487, Test Loss Unfiltered: 0.29933677590562796, Test Loss: 0.03066158407060869\n",
      "Epoch 20 - Loss: 0.02595773698291044, Test Loss Unfiltered: 0.29933677590562796, Test Loss: 0.03066158407060869\n",
      "Epoch 20 - Loss: 0.026233440800704916, Test Loss Unfiltered: 0.29933677590562796, Test Loss: 0.03066158407060869\n",
      "Epoch 20 - Loss: 0.026091514438067766, Test Loss Unfiltered: 0.29933677590562796, Test Loss: 0.03066158407060869\n",
      "Epoch 20 - Loss: 0.026012196488858504, Test Loss Unfiltered: 0.2995389986364651, Test Loss: 0.030694026383986668\n",
      "Epoch 20 - Loss: 0.02609137696227105, Test Loss Unfiltered: 0.2995389986364651, Test Loss: 0.030694026383986668\n",
      "Epoch 20 - Loss: 0.026288467191445147, Test Loss Unfiltered: 0.2995389986364651, Test Loss: 0.030694026383986668\n",
      "Epoch 20 - Loss: 0.026043536229010282, Test Loss Unfiltered: 0.2995389986364651, Test Loss: 0.030694026383986668\n",
      "Epoch 20 - Loss: 0.02590557984588051, Test Loss Unfiltered: 0.2995389986364651, Test Loss: 0.030694026383986668\n",
      "Epoch 20 - Loss: 0.02603696728138806, Test Loss Unfiltered: 0.2989029829685464, Test Loss: 0.030239423047440084\n",
      "Epoch 20 - Loss: 0.026218435910109784, Test Loss Unfiltered: 0.2989029829685464, Test Loss: 0.030239423047440084\n",
      "Epoch 20 - Loss: 0.026162057729120756, Test Loss Unfiltered: 0.2989029829685464, Test Loss: 0.030239423047440084\n",
      "Epoch 20 - Loss: 0.02616430102193642, Test Loss Unfiltered: 0.2989029829685464, Test Loss: 0.030239423047440084\n",
      "Epoch 20 - Loss: 0.025856926801243255, Test Loss Unfiltered: 0.2989029829685464, Test Loss: 0.030239423047440084\n",
      "Epoch 20 - Loss: 0.026208490644192554, Test Loss Unfiltered: 0.29833358995476245, Test Loss: 0.030172334364675313\n",
      "Epoch 20 - Loss: 0.026346523970209326, Test Loss Unfiltered: 0.29833358995476245, Test Loss: 0.030172334364675313\n",
      "Epoch 20 - Loss: 0.02656169352472427, Test Loss Unfiltered: 0.29833358995476245, Test Loss: 0.030172334364675313\n",
      "Epoch 20 - Loss: 0.026251904108074046, Test Loss Unfiltered: 0.29833358995476245, Test Loss: 0.030172334364675313\n",
      "Epoch 20 - Loss: 0.025829513204652505, Test Loss Unfiltered: 0.29833358995476245, Test Loss: 0.030172334364675313\n",
      "Epoch 21 - Loss: 0.025285934005617225, Test Loss Unfiltered: 0.29880898818694657, Test Loss: 0.030139653664419484\n",
      "Epoch 21 - Loss: 0.025163663112717578, Test Loss Unfiltered: 0.29880898818694657, Test Loss: 0.030139653664419484\n",
      "Epoch 21 - Loss: 0.02506399972987908, Test Loss Unfiltered: 0.29880898818694657, Test Loss: 0.030139653664419484\n",
      "Epoch 21 - Loss: 0.025461243897090764, Test Loss Unfiltered: 0.29880898818694657, Test Loss: 0.030139653664419484\n",
      "Epoch 21 - Loss: 0.025138845778807567, Test Loss Unfiltered: 0.29880898818694657, Test Loss: 0.030139653664419484\n",
      "Epoch 21 - Loss: 0.025465823488105815, Test Loss Unfiltered: 0.29918098802242354, Test Loss: 0.030462076816542057\n",
      "Epoch 21 - Loss: 0.0254971528587921, Test Loss Unfiltered: 0.29918098802242354, Test Loss: 0.030462076816542057\n",
      "Epoch 21 - Loss: 0.0251587190353928, Test Loss Unfiltered: 0.29918098802242354, Test Loss: 0.030462076816542057\n",
      "Epoch 21 - Loss: 0.025657146823526666, Test Loss Unfiltered: 0.29918098802242354, Test Loss: 0.030462076816542057\n",
      "Epoch 21 - Loss: 0.025497317496561735, Test Loss Unfiltered: 0.29918098802242354, Test Loss: 0.030462076816542057\n",
      "Epoch 21 - Loss: 0.02596582949308413, Test Loss Unfiltered: 0.2995193306924175, Test Loss: 0.030667113857219992\n",
      "Epoch 21 - Loss: 0.025631984540270002, Test Loss Unfiltered: 0.2995193306924175, Test Loss: 0.030667113857219992\n",
      "Epoch 21 - Loss: 0.025800976146315553, Test Loss Unfiltered: 0.2995193306924175, Test Loss: 0.030667113857219992\n",
      "Epoch 21 - Loss: 0.025873837062934682, Test Loss Unfiltered: 0.2995193306924175, Test Loss: 0.030667113857219992\n",
      "Epoch 21 - Loss: 0.02583161696121889, Test Loss Unfiltered: 0.2995193306924175, Test Loss: 0.030667113857219992\n",
      "Epoch 21 - Loss: 0.025982385185036642, Test Loss Unfiltered: 0.29927211487780964, Test Loss: 0.029943345825922382\n",
      "Epoch 21 - Loss: 0.025706622484299516, Test Loss Unfiltered: 0.29927211487780964, Test Loss: 0.029943345825922382\n",
      "Epoch 21 - Loss: 0.025878807241835354, Test Loss Unfiltered: 0.29927211487780964, Test Loss: 0.029943345825922382\n",
      "Epoch 21 - Loss: 0.026019402671392817, Test Loss Unfiltered: 0.29927211487780964, Test Loss: 0.029943345825922382\n",
      "Epoch 21 - Loss: 0.02598591984742826, Test Loss Unfiltered: 0.29927211487780964, Test Loss: 0.029943345825922382\n",
      "Epoch 21 - Loss: 0.026002865318801038, Test Loss Unfiltered: 0.2990634596906266, Test Loss: 0.030754353104919228\n",
      "Epoch 21 - Loss: 0.026120859789625313, Test Loss Unfiltered: 0.2990634596906266, Test Loss: 0.030754353104919228\n",
      "Epoch 21 - Loss: 0.026055413209781948, Test Loss Unfiltered: 0.2990634596906266, Test Loss: 0.030754353104919228\n",
      "Epoch 21 - Loss: 0.02623352520788389, Test Loss Unfiltered: 0.2990634596906266, Test Loss: 0.030754353104919228\n",
      "Epoch 21 - Loss: 0.026243660070389984, Test Loss Unfiltered: 0.2990634596906266, Test Loss: 0.030754353104919228\n",
      "Epoch 22 - Loss: 0.02476543604240265, Test Loss Unfiltered: 0.29851810182160404, Test Loss: 0.029874339892340097\n",
      "Epoch 22 - Loss: 0.024518407493055786, Test Loss Unfiltered: 0.29851810182160404, Test Loss: 0.029874339892340097\n",
      "Epoch 22 - Loss: 0.025040576572204237, Test Loss Unfiltered: 0.29851810182160404, Test Loss: 0.029874339892340097\n",
      "Epoch 22 - Loss: 0.024980828829392406, Test Loss Unfiltered: 0.29851810182160404, Test Loss: 0.029874339892340097\n",
      "Epoch 22 - Loss: 0.0251180936018744, Test Loss Unfiltered: 0.29851810182160404, Test Loss: 0.029874339892340097\n",
      "Epoch 22 - Loss: 0.025245634775228565, Test Loss Unfiltered: 0.29935606638858875, Test Loss: 0.03006716663922979\n",
      "Epoch 22 - Loss: 0.024965148953344767, Test Loss Unfiltered: 0.29935606638858875, Test Loss: 0.03006716663922979\n",
      "Epoch 22 - Loss: 0.025186722284908276, Test Loss Unfiltered: 0.29935606638858875, Test Loss: 0.03006716663922979\n",
      "Epoch 22 - Loss: 0.025548667958262786, Test Loss Unfiltered: 0.29935606638858875, Test Loss: 0.03006716663922979\n",
      "Epoch 22 - Loss: 0.025321316174385607, Test Loss Unfiltered: 0.29935606638858875, Test Loss: 0.03006716663922979\n",
      "Epoch 22 - Loss: 0.025234191640760694, Test Loss Unfiltered: 0.29955045834074767, Test Loss: 0.030125480655980176\n",
      "Epoch 22 - Loss: 0.025687706795412883, Test Loss Unfiltered: 0.29955045834074767, Test Loss: 0.030125480655980176\n",
      "Epoch 22 - Loss: 0.025452775327377435, Test Loss Unfiltered: 0.29955045834074767, Test Loss: 0.030125480655980176\n",
      "Epoch 22 - Loss: 0.025228410028452466, Test Loss Unfiltered: 0.29955045834074767, Test Loss: 0.030125480655980176\n",
      "Epoch 22 - Loss: 0.025514262545345345, Test Loss Unfiltered: 0.29955045834074767, Test Loss: 0.030125480655980176\n",
      "Epoch 22 - Loss: 0.02595550016768743, Test Loss Unfiltered: 0.30022942061515073, Test Loss: 0.03085359235058693\n",
      "Epoch 22 - Loss: 0.025548002203961886, Test Loss Unfiltered: 0.30022942061515073, Test Loss: 0.03085359235058693\n",
      "Epoch 22 - Loss: 0.02544449528053664, Test Loss Unfiltered: 0.30022942061515073, Test Loss: 0.03085359235058693\n",
      "Epoch 22 - Loss: 0.025531430456330866, Test Loss Unfiltered: 0.30022942061515073, Test Loss: 0.03085359235058693\n",
      "Epoch 22 - Loss: 0.025663102346902243, Test Loss Unfiltered: 0.30022942061515073, Test Loss: 0.03085359235058693\n",
      "Epoch 22 - Loss: 0.02513504779413602, Test Loss Unfiltered: 0.29956822976713937, Test Loss: 0.03047869021416627\n",
      "Epoch 22 - Loss: 0.025436452521906797, Test Loss Unfiltered: 0.29956822976713937, Test Loss: 0.03047869021416627\n",
      "Epoch 22 - Loss: 0.026041897792539483, Test Loss Unfiltered: 0.29956822976713937, Test Loss: 0.03047869021416627\n",
      "Epoch 22 - Loss: 0.02567089452485328, Test Loss Unfiltered: 0.29956822976713937, Test Loss: 0.03047869021416627\n",
      "Epoch 22 - Loss: 0.02577463695264219, Test Loss Unfiltered: 0.29956822976713937, Test Loss: 0.03047869021416627\n",
      "Epoch 23 - Loss: 0.023981180673726104, Test Loss Unfiltered: 0.29975158834275, Test Loss: 0.03010934340123717\n",
      "Epoch 23 - Loss: 0.024746128799913863, Test Loss Unfiltered: 0.29975158834275, Test Loss: 0.03010934340123717\n",
      "Epoch 23 - Loss: 0.024705546790882712, Test Loss Unfiltered: 0.29975158834275, Test Loss: 0.03010934340123717\n",
      "Epoch 23 - Loss: 0.02491858029680376, Test Loss Unfiltered: 0.29975158834275, Test Loss: 0.03010934340123717\n",
      "Epoch 23 - Loss: 0.02467982439177053, Test Loss Unfiltered: 0.29975158834275, Test Loss: 0.03010934340123717\n",
      "Epoch 23 - Loss: 0.02494100913565811, Test Loss Unfiltered: 0.2987320713514354, Test Loss: 0.030569624546278314\n",
      "Epoch 23 - Loss: 0.024890911580006586, Test Loss Unfiltered: 0.2987320713514354, Test Loss: 0.030569624546278314\n",
      "Epoch 23 - Loss: 0.0246574330958565, Test Loss Unfiltered: 0.2987320713514354, Test Loss: 0.030569624546278314\n",
      "Epoch 23 - Loss: 0.024914615892801164, Test Loss Unfiltered: 0.2987320713514354, Test Loss: 0.030569624546278314\n",
      "Epoch 23 - Loss: 0.02497625626027064, Test Loss Unfiltered: 0.2987320713514354, Test Loss: 0.030569624546278314\n",
      "Epoch 23 - Loss: 0.024810261082433917, Test Loss Unfiltered: 0.29924449040533624, Test Loss: 0.029851858389002613\n",
      "Epoch 23 - Loss: 0.0254207234784893, Test Loss Unfiltered: 0.29924449040533624, Test Loss: 0.029851858389002613\n",
      "Epoch 23 - Loss: 0.025353720908354405, Test Loss Unfiltered: 0.29924449040533624, Test Loss: 0.029851858389002613\n",
      "Epoch 23 - Loss: 0.025102045935788634, Test Loss Unfiltered: 0.29924449040533624, Test Loss: 0.029851858389002613\n",
      "Epoch 23 - Loss: 0.024888128767298862, Test Loss Unfiltered: 0.29924449040533624, Test Loss: 0.029851858389002613\n",
      "Epoch 23 - Loss: 0.025187899164390716, Test Loss Unfiltered: 0.2991012759284504, Test Loss: 0.030198775457414256\n",
      "Epoch 23 - Loss: 0.025217847487780054, Test Loss Unfiltered: 0.2991012759284504, Test Loss: 0.030198775457414256\n",
      "Epoch 23 - Loss: 0.025453210735661192, Test Loss Unfiltered: 0.2991012759284504, Test Loss: 0.030198775457414256\n",
      "Epoch 23 - Loss: 0.025279494234753622, Test Loss Unfiltered: 0.2991012759284504, Test Loss: 0.030198775457414256\n",
      "Epoch 23 - Loss: 0.025501110360210886, Test Loss Unfiltered: 0.2991012759284504, Test Loss: 0.030198775457414256\n",
      "Epoch 23 - Loss: 0.025440851818036694, Test Loss Unfiltered: 0.29772125752560175, Test Loss: 0.029745390478233814\n",
      "Epoch 23 - Loss: 0.024974118772603332, Test Loss Unfiltered: 0.29772125752560175, Test Loss: 0.029745390478233814\n",
      "Epoch 23 - Loss: 0.02547173086856921, Test Loss Unfiltered: 0.29772125752560175, Test Loss: 0.029745390478233814\n",
      "Epoch 23 - Loss: 0.025217724413621474, Test Loss Unfiltered: 0.29772125752560175, Test Loss: 0.029745390478233814\n",
      "Epoch 23 - Loss: 0.02551060009167629, Test Loss Unfiltered: 0.29772125752560175, Test Loss: 0.029745390478233814\n",
      "Epoch 24 - Loss: 0.024203081785400128, Test Loss Unfiltered: 0.2997943800550619, Test Loss: 0.030184310423107628\n",
      "Epoch 24 - Loss: 0.024117513301883105, Test Loss Unfiltered: 0.2997943800550619, Test Loss: 0.030184310423107628\n",
      "Epoch 24 - Loss: 0.024419599491583892, Test Loss Unfiltered: 0.2997943800550619, Test Loss: 0.030184310423107628\n",
      "Epoch 24 - Loss: 0.024517713072728483, Test Loss Unfiltered: 0.2997943800550619, Test Loss: 0.030184310423107628\n",
      "Epoch 24 - Loss: 0.024242933564711282, Test Loss Unfiltered: 0.2997943800550619, Test Loss: 0.030184310423107628\n",
      "Epoch 24 - Loss: 0.024519992579750276, Test Loss Unfiltered: 0.29963455571529485, Test Loss: 0.030455220758222542\n",
      "Epoch 24 - Loss: 0.02452198649621483, Test Loss Unfiltered: 0.29963455571529485, Test Loss: 0.030455220758222542\n",
      "Epoch 24 - Loss: 0.02456985723680661, Test Loss Unfiltered: 0.29963455571529485, Test Loss: 0.030455220758222542\n",
      "Epoch 24 - Loss: 0.024827676686206744, Test Loss Unfiltered: 0.29963455571529485, Test Loss: 0.030455220758222542\n",
      "Epoch 24 - Loss: 0.02469302505705372, Test Loss Unfiltered: 0.29963455571529485, Test Loss: 0.030455220758222542\n",
      "Epoch 24 - Loss: 0.024831001302855385, Test Loss Unfiltered: 0.298440211426788, Test Loss: 0.030197309994724388\n",
      "Epoch 24 - Loss: 0.025020201428325787, Test Loss Unfiltered: 0.298440211426788, Test Loss: 0.030197309994724388\n",
      "Epoch 24 - Loss: 0.024904381183302297, Test Loss Unfiltered: 0.298440211426788, Test Loss: 0.030197309994724388\n",
      "Epoch 24 - Loss: 0.02508479304547772, Test Loss Unfiltered: 0.298440211426788, Test Loss: 0.030197309994724388\n",
      "Epoch 24 - Loss: 0.02490610454619858, Test Loss Unfiltered: 0.298440211426788, Test Loss: 0.030197309994724388\n",
      "Epoch 24 - Loss: 0.024530889254318136, Test Loss Unfiltered: 0.29886648817761685, Test Loss: 0.029958515383555987\n",
      "Epoch 24 - Loss: 0.024686619269007046, Test Loss Unfiltered: 0.29886648817761685, Test Loss: 0.029958515383555987\n",
      "Epoch 24 - Loss: 0.024938933792722665, Test Loss Unfiltered: 0.29886648817761685, Test Loss: 0.029958515383555987\n",
      "Epoch 24 - Loss: 0.024973340792208434, Test Loss Unfiltered: 0.29886648817761685, Test Loss: 0.029958515383555987\n",
      "Epoch 24 - Loss: 0.024931293879059884, Test Loss Unfiltered: 0.29886648817761685, Test Loss: 0.029958515383555987\n",
      "Epoch 24 - Loss: 0.025048130250880218, Test Loss Unfiltered: 0.2986729169442163, Test Loss: 0.03061993028424138\n",
      "Epoch 24 - Loss: 0.025025229043907058, Test Loss Unfiltered: 0.2986729169442163, Test Loss: 0.03061993028424138\n",
      "Epoch 24 - Loss: 0.02491261391180784, Test Loss Unfiltered: 0.2986729169442163, Test Loss: 0.03061993028424138\n",
      "Epoch 24 - Loss: 0.02514703247510347, Test Loss Unfiltered: 0.2986729169442163, Test Loss: 0.03061993028424138\n",
      "Epoch 24 - Loss: 0.025245180030544736, Test Loss Unfiltered: 0.2986729169442163, Test Loss: 0.03061993028424138\n",
      "Epoch 25 - Loss: 0.023531553031703522, Test Loss Unfiltered: 0.2998013864798753, Test Loss: 0.030168029038437027\n",
      "Epoch 25 - Loss: 0.0241151893091069, Test Loss Unfiltered: 0.2998013864798753, Test Loss: 0.030168029038437027\n",
      "Epoch 25 - Loss: 0.02400688425477646, Test Loss Unfiltered: 0.2998013864798753, Test Loss: 0.030168029038437027\n",
      "Epoch 25 - Loss: 0.023947740932570034, Test Loss Unfiltered: 0.2998013864798753, Test Loss: 0.030168029038437027\n",
      "Epoch 25 - Loss: 0.024485025459333017, Test Loss Unfiltered: 0.2998013864798753, Test Loss: 0.030168029038437027\n",
      "Epoch 25 - Loss: 0.024396009562555353, Test Loss Unfiltered: 0.2988301965852812, Test Loss: 0.030009359027264933\n",
      "Epoch 25 - Loss: 0.02427056912659728, Test Loss Unfiltered: 0.2988301965852812, Test Loss: 0.030009359027264933\n",
      "Epoch 25 - Loss: 0.024245870117859874, Test Loss Unfiltered: 0.2988301965852812, Test Loss: 0.030009359027264933\n",
      "Epoch 25 - Loss: 0.024680019487306047, Test Loss Unfiltered: 0.2988301965852812, Test Loss: 0.030009359027264933\n",
      "Epoch 25 - Loss: 0.024462187410687838, Test Loss Unfiltered: 0.2988301965852812, Test Loss: 0.030009359027264933\n",
      "Epoch 25 - Loss: 0.024204205781159435, Test Loss Unfiltered: 0.29939350423283834, Test Loss: 0.03020136452912607\n",
      "Epoch 25 - Loss: 0.02449081058894626, Test Loss Unfiltered: 0.29939350423283834, Test Loss: 0.03020136452912607\n",
      "Epoch 25 - Loss: 0.024470963203193988, Test Loss Unfiltered: 0.29939350423283834, Test Loss: 0.03020136452912607\n",
      "Epoch 25 - Loss: 0.02486056215469273, Test Loss Unfiltered: 0.29939350423283834, Test Loss: 0.03020136452912607\n",
      "Epoch 25 - Loss: 0.024316297693530255, Test Loss Unfiltered: 0.29939350423283834, Test Loss: 0.03020136452912607\n",
      "Epoch 25 - Loss: 0.024555481113433694, Test Loss Unfiltered: 0.2993468741337733, Test Loss: 0.029910086230676255\n",
      "Epoch 25 - Loss: 0.02476948113090018, Test Loss Unfiltered: 0.2993468741337733, Test Loss: 0.029910086230676255\n",
      "Epoch 25 - Loss: 0.024696081664380247, Test Loss Unfiltered: 0.2993468741337733, Test Loss: 0.029910086230676255\n",
      "Epoch 25 - Loss: 0.024679847269612205, Test Loss Unfiltered: 0.2993468741337733, Test Loss: 0.029910086230676255\n",
      "Epoch 25 - Loss: 0.0245235179027342, Test Loss Unfiltered: 0.2993468741337733, Test Loss: 0.029910086230676255\n",
      "Epoch 25 - Loss: 0.02488877743984332, Test Loss Unfiltered: 0.29857823494693914, Test Loss: 0.02996178153698154\n",
      "Epoch 25 - Loss: 0.024528336305930817, Test Loss Unfiltered: 0.29857823494693914, Test Loss: 0.02996178153698154\n",
      "Epoch 25 - Loss: 0.024995956717204074, Test Loss Unfiltered: 0.29857823494693914, Test Loss: 0.02996178153698154\n",
      "Epoch 25 - Loss: 0.024921488402437634, Test Loss Unfiltered: 0.29857823494693914, Test Loss: 0.02996178153698154\n",
      "Epoch 25 - Loss: 0.024970239905082438, Test Loss Unfiltered: 0.29857823494693914, Test Loss: 0.02996178153698154\n",
      "Epoch 26 - Loss: 0.023492353125380352, Test Loss Unfiltered: 0.2990241805668481, Test Loss: 0.0300834992177343\n",
      "Epoch 26 - Loss: 0.02362191655583338, Test Loss Unfiltered: 0.2990241805668481, Test Loss: 0.0300834992177343\n",
      "Epoch 26 - Loss: 0.023762976543998185, Test Loss Unfiltered: 0.2990241805668481, Test Loss: 0.0300834992177343\n",
      "Epoch 26 - Loss: 0.023891637607129135, Test Loss Unfiltered: 0.2990241805668481, Test Loss: 0.0300834992177343\n",
      "Epoch 26 - Loss: 0.02387609141956585, Test Loss Unfiltered: 0.2990241805668481, Test Loss: 0.0300834992177343\n",
      "Epoch 26 - Loss: 0.023976344063190953, Test Loss Unfiltered: 0.29907341637637797, Test Loss: 0.030091416408206964\n",
      "Epoch 26 - Loss: 0.023992502123047543, Test Loss Unfiltered: 0.29907341637637797, Test Loss: 0.030091416408206964\n",
      "Epoch 26 - Loss: 0.024259339336157454, Test Loss Unfiltered: 0.29907341637637797, Test Loss: 0.030091416408206964\n",
      "Epoch 26 - Loss: 0.0242021471208247, Test Loss Unfiltered: 0.29907341637637797, Test Loss: 0.030091416408206964\n",
      "Epoch 26 - Loss: 0.023866902561354403, Test Loss Unfiltered: 0.29907341637637797, Test Loss: 0.030091416408206964\n",
      "Epoch 26 - Loss: 0.024406525147885442, Test Loss Unfiltered: 0.29972296237176044, Test Loss: 0.030253549845589773\n",
      "Epoch 26 - Loss: 0.024180529550421066, Test Loss Unfiltered: 0.29972296237176044, Test Loss: 0.030253549845589773\n",
      "Epoch 26 - Loss: 0.024376113478979448, Test Loss Unfiltered: 0.29972296237176044, Test Loss: 0.030253549845589773\n",
      "Epoch 26 - Loss: 0.024081828765645578, Test Loss Unfiltered: 0.29972296237176044, Test Loss: 0.030253549845589773\n",
      "Epoch 26 - Loss: 0.02434143278472825, Test Loss Unfiltered: 0.29972296237176044, Test Loss: 0.030253549845589773\n",
      "Epoch 26 - Loss: 0.024423007629051304, Test Loss Unfiltered: 0.2981496176904067, Test Loss: 0.0300227070648316\n",
      "Epoch 26 - Loss: 0.024413600844136765, Test Loss Unfiltered: 0.2981496176904067, Test Loss: 0.0300227070648316\n",
      "Epoch 26 - Loss: 0.024501904092456516, Test Loss Unfiltered: 0.2981496176904067, Test Loss: 0.0300227070648316\n",
      "Epoch 26 - Loss: 0.02453632231949421, Test Loss Unfiltered: 0.2981496176904067, Test Loss: 0.0300227070648316\n",
      "Epoch 26 - Loss: 0.024496727404638832, Test Loss Unfiltered: 0.2981496176904067, Test Loss: 0.0300227070648316\n",
      "Epoch 26 - Loss: 0.024420162601721442, Test Loss Unfiltered: 0.2987157755317999, Test Loss: 0.03011020899079668\n",
      "Epoch 26 - Loss: 0.02447632762816742, Test Loss Unfiltered: 0.2987157755317999, Test Loss: 0.03011020899079668\n",
      "Epoch 26 - Loss: 0.024383265177672902, Test Loss Unfiltered: 0.2987157755317999, Test Loss: 0.03011020899079668\n",
      "Epoch 26 - Loss: 0.024543081350044637, Test Loss Unfiltered: 0.2987157755317999, Test Loss: 0.03011020899079668\n",
      "Epoch 26 - Loss: 0.024716423006787284, Test Loss Unfiltered: 0.2987157755317999, Test Loss: 0.03011020899079668\n",
      "Epoch 27 - Loss: 0.023207002427434426, Test Loss Unfiltered: 0.30004917626005156, Test Loss: 0.030117333685272023\n",
      "Epoch 27 - Loss: 0.02327505758284939, Test Loss Unfiltered: 0.30004917626005156, Test Loss: 0.030117333685272023\n",
      "Epoch 27 - Loss: 0.02353230708767699, Test Loss Unfiltered: 0.30004917626005156, Test Loss: 0.030117333685272023\n",
      "Epoch 27 - Loss: 0.023757151664522625, Test Loss Unfiltered: 0.30004917626005156, Test Loss: 0.030117333685272023\n",
      "Epoch 27 - Loss: 0.023342175605581016, Test Loss Unfiltered: 0.30004917626005156, Test Loss: 0.030117333685272023\n",
      "Epoch 27 - Loss: 0.023729088916174007, Test Loss Unfiltered: 0.30005638978673566, Test Loss: 0.03031870663353005\n",
      "Epoch 27 - Loss: 0.02378780531130703, Test Loss Unfiltered: 0.30005638978673566, Test Loss: 0.03031870663353005\n",
      "Epoch 27 - Loss: 0.023862182802401776, Test Loss Unfiltered: 0.30005638978673566, Test Loss: 0.03031870663353005\n",
      "Epoch 27 - Loss: 0.023782564616320296, Test Loss Unfiltered: 0.30005638978673566, Test Loss: 0.03031870663353005\n",
      "Epoch 27 - Loss: 0.023911944191220297, Test Loss Unfiltered: 0.30005638978673566, Test Loss: 0.03031870663353005\n",
      "Epoch 27 - Loss: 0.024413144723729987, Test Loss Unfiltered: 0.29851380408198697, Test Loss: 0.02975660724154698\n",
      "Epoch 27 - Loss: 0.023767764831365834, Test Loss Unfiltered: 0.29851380408198697, Test Loss: 0.02975660724154698\n",
      "Epoch 27 - Loss: 0.023896182386118642, Test Loss Unfiltered: 0.29851380408198697, Test Loss: 0.02975660724154698\n",
      "Epoch 27 - Loss: 0.023984294405592174, Test Loss Unfiltered: 0.29851380408198697, Test Loss: 0.02975660724154698\n",
      "Epoch 27 - Loss: 0.024084685734654276, Test Loss Unfiltered: 0.29851380408198697, Test Loss: 0.02975660724154698\n",
      "Epoch 27 - Loss: 0.023792982230054643, Test Loss Unfiltered: 0.30025281929987846, Test Loss: 0.02978189233346906\n",
      "Epoch 27 - Loss: 0.024110139937530046, Test Loss Unfiltered: 0.30025281929987846, Test Loss: 0.02978189233346906\n",
      "Epoch 27 - Loss: 0.023843883085536994, Test Loss Unfiltered: 0.30025281929987846, Test Loss: 0.02978189233346906\n",
      "Epoch 27 - Loss: 0.024370259601879874, Test Loss Unfiltered: 0.30025281929987846, Test Loss: 0.02978189233346906\n",
      "Epoch 27 - Loss: 0.024302539029859672, Test Loss Unfiltered: 0.30025281929987846, Test Loss: 0.02978189233346906\n",
      "Epoch 27 - Loss: 0.024333000396785643, Test Loss Unfiltered: 0.29983080582162935, Test Loss: 0.02998235602616144\n",
      "Epoch 27 - Loss: 0.024251933019000672, Test Loss Unfiltered: 0.29983080582162935, Test Loss: 0.02998235602616144\n",
      "Epoch 27 - Loss: 0.024236131613374484, Test Loss Unfiltered: 0.29983080582162935, Test Loss: 0.02998235602616144\n",
      "Epoch 27 - Loss: 0.02452628143707643, Test Loss Unfiltered: 0.29983080582162935, Test Loss: 0.02998235602616144\n",
      "Epoch 27 - Loss: 0.024747188705589406, Test Loss Unfiltered: 0.29983080582162935, Test Loss: 0.02998235602616144\n",
      "Epoch 28 - Loss: 0.022745953854278918, Test Loss Unfiltered: 0.299670470616058, Test Loss: 0.02987664664896809\n",
      "Epoch 28 - Loss: 0.023039755705706388, Test Loss Unfiltered: 0.299670470616058, Test Loss: 0.02987664664896809\n",
      "Epoch 28 - Loss: 0.02328204774308699, Test Loss Unfiltered: 0.299670470616058, Test Loss: 0.02987664664896809\n",
      "Epoch 28 - Loss: 0.023293694440787896, Test Loss Unfiltered: 0.299670470616058, Test Loss: 0.02987664664896809\n",
      "Epoch 28 - Loss: 0.0233507613107744, Test Loss Unfiltered: 0.299670470616058, Test Loss: 0.02987664664896809\n",
      "Epoch 28 - Loss: 0.023450534292922192, Test Loss Unfiltered: 0.2987931659760707, Test Loss: 0.030274136445273558\n",
      "Epoch 28 - Loss: 0.02362317116299408, Test Loss Unfiltered: 0.2987931659760707, Test Loss: 0.030274136445273558\n",
      "Epoch 28 - Loss: 0.02362488222928717, Test Loss Unfiltered: 0.2987931659760707, Test Loss: 0.030274136445273558\n",
      "Epoch 28 - Loss: 0.02345125092912639, Test Loss Unfiltered: 0.2987931659760707, Test Loss: 0.030274136445273558\n",
      "Epoch 28 - Loss: 0.023993794795879937, Test Loss Unfiltered: 0.2987931659760707, Test Loss: 0.030274136445273558\n",
      "Epoch 28 - Loss: 0.02387172441795429, Test Loss Unfiltered: 0.29954237061115735, Test Loss: 0.029965638373080195\n",
      "Epoch 28 - Loss: 0.023772584155487827, Test Loss Unfiltered: 0.29954237061115735, Test Loss: 0.029965638373080195\n",
      "Epoch 28 - Loss: 0.023443694102437324, Test Loss Unfiltered: 0.29954237061115735, Test Loss: 0.029965638373080195\n",
      "Epoch 28 - Loss: 0.024056794484004555, Test Loss Unfiltered: 0.29954237061115735, Test Loss: 0.029965638373080195\n",
      "Epoch 28 - Loss: 0.02368718484514135, Test Loss Unfiltered: 0.29954237061115735, Test Loss: 0.029965638373080195\n",
      "Epoch 28 - Loss: 0.02367623976531978, Test Loss Unfiltered: 0.2996690924909929, Test Loss: 0.02964458382448759\n",
      "Epoch 28 - Loss: 0.02401804759290849, Test Loss Unfiltered: 0.2996690924909929, Test Loss: 0.02964458382448759\n",
      "Epoch 28 - Loss: 0.023945409198535314, Test Loss Unfiltered: 0.2996690924909929, Test Loss: 0.02964458382448759\n",
      "Epoch 28 - Loss: 0.023910552379279415, Test Loss Unfiltered: 0.2996690924909929, Test Loss: 0.02964458382448759\n",
      "Epoch 28 - Loss: 0.023993913083132628, Test Loss Unfiltered: 0.2996690924909929, Test Loss: 0.02964458382448759\n",
      "Epoch 28 - Loss: 0.02391080780355972, Test Loss Unfiltered: 0.29912696528516425, Test Loss: 0.030012598378836956\n",
      "Epoch 28 - Loss: 0.023945852224133844, Test Loss Unfiltered: 0.29912696528516425, Test Loss: 0.030012598378836956\n",
      "Epoch 28 - Loss: 0.023768210274422996, Test Loss Unfiltered: 0.29912696528516425, Test Loss: 0.030012598378836956\n",
      "Epoch 28 - Loss: 0.024564849543827073, Test Loss Unfiltered: 0.29912696528516425, Test Loss: 0.030012598378836956\n",
      "Epoch 28 - Loss: 0.024483647995262637, Test Loss Unfiltered: 0.29912696528516425, Test Loss: 0.030012598378836956\n",
      "Epoch 29 - Loss: 0.02260942779076658, Test Loss Unfiltered: 0.29959370094375054, Test Loss: 0.03008534843727016\n",
      "Epoch 29 - Loss: 0.02291298191743671, Test Loss Unfiltered: 0.29959370094375054, Test Loss: 0.03008534843727016\n",
      "Epoch 29 - Loss: 0.0228236941854891, Test Loss Unfiltered: 0.29959370094375054, Test Loss: 0.03008534843727016\n",
      "Epoch 29 - Loss: 0.02309762638228123, Test Loss Unfiltered: 0.29959370094375054, Test Loss: 0.03008534843727016\n",
      "Epoch 29 - Loss: 0.02337372415623321, Test Loss Unfiltered: 0.29959370094375054, Test Loss: 0.03008534843727016\n",
      "Epoch 29 - Loss: 0.023176805572728755, Test Loss Unfiltered: 0.2997683450141045, Test Loss: 0.030185456705055697\n",
      "Epoch 29 - Loss: 0.02314614167211068, Test Loss Unfiltered: 0.2997683450141045, Test Loss: 0.030185456705055697\n",
      "Epoch 29 - Loss: 0.023589553266005148, Test Loss Unfiltered: 0.2997683450141045, Test Loss: 0.030185456705055697\n",
      "Epoch 29 - Loss: 0.023328041750186827, Test Loss Unfiltered: 0.2997683450141045, Test Loss: 0.030185456705055697\n",
      "Epoch 29 - Loss: 0.02350874853435555, Test Loss Unfiltered: 0.2997683450141045, Test Loss: 0.030185456705055697\n",
      "Epoch 29 - Loss: 0.02326764949460595, Test Loss Unfiltered: 0.29871581837507155, Test Loss: 0.030126753425078284\n",
      "Epoch 29 - Loss: 0.02337040123769161, Test Loss Unfiltered: 0.29871581837507155, Test Loss: 0.030126753425078284\n",
      "Epoch 29 - Loss: 0.02347306583578172, Test Loss Unfiltered: 0.29871581837507155, Test Loss: 0.030126753425078284\n",
      "Epoch 29 - Loss: 0.02333561584455784, Test Loss Unfiltered: 0.29871581837507155, Test Loss: 0.030126753425078284\n",
      "Epoch 29 - Loss: 0.023459051086834447, Test Loss Unfiltered: 0.29871581837507155, Test Loss: 0.030126753425078284\n",
      "Epoch 29 - Loss: 0.023773152805219834, Test Loss Unfiltered: 0.2989318368576401, Test Loss: 0.029887468809153966\n",
      "Epoch 29 - Loss: 0.023753358442830913, Test Loss Unfiltered: 0.2989318368576401, Test Loss: 0.029887468809153966\n",
      "Epoch 29 - Loss: 0.02397258112519988, Test Loss Unfiltered: 0.2989318368576401, Test Loss: 0.029887468809153966\n",
      "Epoch 29 - Loss: 0.023888963679904927, Test Loss Unfiltered: 0.2989318368576401, Test Loss: 0.029887468809153966\n",
      "Epoch 29 - Loss: 0.023534501986115484, Test Loss Unfiltered: 0.2989318368576401, Test Loss: 0.029887468809153966\n",
      "Epoch 29 - Loss: 0.023536211896563432, Test Loss Unfiltered: 0.29895865235121194, Test Loss: 0.029661342315567784\n",
      "Epoch 29 - Loss: 0.02383994743493553, Test Loss Unfiltered: 0.29895865235121194, Test Loss: 0.029661342315567784\n",
      "Epoch 29 - Loss: 0.02405549236118997, Test Loss Unfiltered: 0.29895865235121194, Test Loss: 0.029661342315567784\n",
      "Epoch 29 - Loss: 0.023954313749148946, Test Loss Unfiltered: 0.29895865235121194, Test Loss: 0.029661342315567784\n",
      "Epoch 29 - Loss: 0.024147797480138854, Test Loss Unfiltered: 0.29895865235121194, Test Loss: 0.029661342315567784\n",
      "Epoch 30 - Loss: 0.022301587185572645, Test Loss Unfiltered: 0.29870761580333066, Test Loss: 0.029844333275587206\n",
      "Epoch 30 - Loss: 0.022600718796373962, Test Loss Unfiltered: 0.29870761580333066, Test Loss: 0.029844333275587206\n",
      "Epoch 30 - Loss: 0.02270729661653478, Test Loss Unfiltered: 0.29870761580333066, Test Loss: 0.029844333275587206\n",
      "Epoch 30 - Loss: 0.022701691109545674, Test Loss Unfiltered: 0.29870761580333066, Test Loss: 0.029844333275587206\n",
      "Epoch 30 - Loss: 0.022946647655938485, Test Loss Unfiltered: 0.29870761580333066, Test Loss: 0.029844333275587206\n",
      "Epoch 30 - Loss: 0.022846428822790196, Test Loss Unfiltered: 0.29993370117109647, Test Loss: 0.030750200287201292\n",
      "Epoch 30 - Loss: 0.02279381261358683, Test Loss Unfiltered: 0.29993370117109647, Test Loss: 0.030750200287201292\n",
      "Epoch 30 - Loss: 0.02309591497113416, Test Loss Unfiltered: 0.29993370117109647, Test Loss: 0.030750200287201292\n",
      "Epoch 30 - Loss: 0.0231118622787523, Test Loss Unfiltered: 0.29993370117109647, Test Loss: 0.030750200287201292\n",
      "Epoch 30 - Loss: 0.023410529328458392, Test Loss Unfiltered: 0.29993370117109647, Test Loss: 0.030750200287201292\n",
      "Epoch 30 - Loss: 0.023215233823752714, Test Loss Unfiltered: 0.29978397264407763, Test Loss: 0.030349094883182316\n",
      "Epoch 30 - Loss: 0.023201447151077883, Test Loss Unfiltered: 0.29978397264407763, Test Loss: 0.030349094883182316\n",
      "Epoch 30 - Loss: 0.02356760892559039, Test Loss Unfiltered: 0.29978397264407763, Test Loss: 0.030349094883182316\n",
      "Epoch 30 - Loss: 0.023341514086222547, Test Loss Unfiltered: 0.29978397264407763, Test Loss: 0.030349094883182316\n",
      "Epoch 30 - Loss: 0.023506464376344082, Test Loss Unfiltered: 0.29978397264407763, Test Loss: 0.030349094883182316\n",
      "Epoch 30 - Loss: 0.023585240354145016, Test Loss Unfiltered: 0.30015860611245726, Test Loss: 0.029657802642123837\n",
      "Epoch 30 - Loss: 0.023541315345119197, Test Loss Unfiltered: 0.30015860611245726, Test Loss: 0.029657802642123837\n",
      "Epoch 30 - Loss: 0.023214548632617318, Test Loss Unfiltered: 0.30015860611245726, Test Loss: 0.029657802642123837\n",
      "Epoch 30 - Loss: 0.023505313172706294, Test Loss Unfiltered: 0.30015860611245726, Test Loss: 0.029657802642123837\n",
      "Epoch 30 - Loss: 0.023446664858807136, Test Loss Unfiltered: 0.30015860611245726, Test Loss: 0.029657802642123837\n",
      "Epoch 30 - Loss: 0.02356163666548162, Test Loss Unfiltered: 0.2991910539446328, Test Loss: 0.029989645705419076\n",
      "Epoch 30 - Loss: 0.02382704670261222, Test Loss Unfiltered: 0.2991910539446328, Test Loss: 0.029989645705419076\n",
      "Epoch 30 - Loss: 0.023511497745709754, Test Loss Unfiltered: 0.2991910539446328, Test Loss: 0.029989645705419076\n",
      "Epoch 30 - Loss: 0.023802565623971907, Test Loss Unfiltered: 0.2991910539446328, Test Loss: 0.029989645705419076\n",
      "Epoch 30 - Loss: 0.02372919073006607, Test Loss Unfiltered: 0.2991910539446328, Test Loss: 0.029989645705419076\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 5\n",
    "\n",
    "obs_buffer = []\n",
    "act_buffer = []\n",
    "\n",
    "gpumodel.train()\n",
    "\n",
    "for epoch in range(30):\n",
    "    batch = 0\n",
    "    total_loss = 0\n",
    "    obs_count = 0\n",
    "\n",
    "    for _obs, _act, _add_data in Train_Data_Loader:\n",
    "        # OBS BATCHING \n",
    "        obs = _obs[0].cuda()\n",
    "        act = _act[0, :, 0:5].float().cuda()\n",
    "\n",
    "        if obs.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        obs_buffer.append(obs)\n",
    "        act_buffer.append(act)\n",
    "\n",
    "        if len(obs_buffer) < BUFFER_SIZE:\n",
    "            continue\n",
    "\n",
    "        obs = torch.cat(obs_buffer)\n",
    "        act = torch.cat(act_buffer)\n",
    "\n",
    "        obs_buffer = []\n",
    "        act_buffer = []\n",
    "\n",
    "        # TRAINING\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(obs)\n",
    "        \n",
    "        loss = criterion(y_pred, act)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # LOGGING\n",
    "        obs_count += len(obs)\n",
    "        total_loss += loss.item() * len(obs)\n",
    "\n",
    "\n",
    "        batch += 1\n",
    "        if batch % 1000 == 0:\n",
    "            if (batch - 1000) % 5000 == 0:\n",
    "                start_test = time()\n",
    "                test_loss_unfiltered = test_model(gpumodel, Test_Data_Loader_Unfiltered)\n",
    "                test_loss = test_model(gpumodel, Test_Data_Loader)\n",
    "                test_loss_human = test_model(gpumodel, Test_Data_Loader_Human)\n",
    "                gpumodel.train()\n",
    "\n",
    "            print(f'Epoch {epoch + 1} - Loss: {total_loss / obs_count}, Test Loss Unfiltered: {test_loss_unfiltered}, Test Loss: {test_loss}')\n",
    "            wandb.log({\"loss_MSE\": total_loss/obs_count,\n",
    "                        \"test_loss_unfiltered_MSE\": test_loss_unfiltered,\n",
    "                        \"test_loss_MSE\": test_loss,\n",
    "                        \"test_loss_human_MSE\": test_loss_human})\n",
    "\n",
    "            total_loss = 0\n",
    "            obs_count = 0\n",
    "    \n",
    "\n",
    "    #scheduler.step()\n",
    "    if (epoch % 2) == 0:\n",
    "        torch.save(gpumodel.state_dict(), f\"trained_networks/{wandb.run.name}/{wandb.run.name} ({epoch} epochs).pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05441522278061852"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(gpumodel, Test_Data_Loader_Human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 26.654266357421875, Correct: tensor([0.9120, 0.8223, 0.8248, 0.4793, 0.8872, 0.9554, 0.9545, 0.9802, 0.2843],\n",
      "       device='cuda:0'), Correct On Ground: tensor([0.9169, 0.8199, 0.9977, 0.4163, 1.0000, 0.9867, 0.9555, 0.9723, 0.0000],\n",
      "       device='cuda:0'), On Ground: 0.715702479338843\n",
      "[[[ 183.    6.    6.]\n",
      "  [  30.  359.   33.]\n",
      "  [   5.   64. 1046.]]\n",
      "\n",
      " [[ 297.   45.    3.]\n",
      "  [  67.  608.  118.]\n",
      "  [  10.   69.  515.]]\n",
      "\n",
      " [[   0.    0.    0.]\n",
      "  [   1. 1728.    3.]\n",
      "  [   0.    0.    0.]]\n",
      "\n",
      " [[   0.    0.    0.]\n",
      "  [ 368.  721.  643.]\n",
      "  [   0.    0.    0.]]\n",
      "\n",
      " [[   0.    0.    0.]\n",
      "  [   0. 1732.    0.]\n",
      "  [   0.    0.    0.]]\n",
      "\n",
      " [[1709.   23.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]]\n",
      "\n",
      " [[1380.   50.    0.]\n",
      "  [  27.  275.    0.]\n",
      "  [   0.    0.    0.]]\n",
      "\n",
      " [[1684.   48.    0.]\n",
      "  [   0.    0.    0.]\n",
      "  [   0.    0.    0.]]]\n"
     ]
    }
   ],
   "source": [
    "conf_mtx = torch.zeros((8,3,3)).cuda()\n",
    "CONF_MAT = True\n",
    "\n",
    "gpumodel.eval()\n",
    "\n",
    "total_loss = 0\n",
    "obs_count = 0\n",
    "total_correct = torch.zeros(9).cuda()\n",
    "\n",
    "correct_on_ground = torch.zeros(9).cuda()\n",
    "total_on_ground = 0\n",
    "\n",
    "for _obs, _act, _add_data in Test_Data_Loader:\n",
    "    # EVALUATION\n",
    "    obs = _obs[0].cuda()\n",
    "    act = torch.cat((_act[0], _add_data[0][:,0:1]), dim=1).long().cuda()\n",
    "    add_data = _add_data[0].long()\n",
    "\n",
    "    if obs.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(obs)\n",
    "\n",
    "    y_pred = model(obs)\n",
    "    pred_act = torch.zeros(obs.shape[0], 9).cuda()\n",
    "\n",
    "    loss = 0\n",
    "    for i in range(9):\n",
    "        loss += criterion(y_pred[i], act[:, i])\n",
    "\n",
    "        pred_act[:, i] = torch.argmax(y_pred[i], dim=1)\n",
    "\n",
    "\n",
    "    # LOGGING\n",
    "    obs_count += len(obs)\n",
    "    total_loss += loss.item() * len(obs)\n",
    "\n",
    "    correct = act == pred_act\n",
    "    total_correct += torch.sum(correct, dim=0)\n",
    "\n",
    "    on_ground = pred_act[:,8]\n",
    "\n",
    "    #print(correct)\n",
    "    #print(on_ground.bool())\n",
    "\n",
    "    total_on_ground += torch.sum(on_ground == 1).item()\n",
    "\n",
    "\n",
    "    correct_on_ground += torch.sum(correct[on_ground == 1], dim=0)\n",
    "\n",
    "    if CONF_MAT:\n",
    "        for i in range(obs.shape[0]):\n",
    "            for j in range(8):\n",
    "                if on_ground[i] == 1:\n",
    "                    conf_mtx[j, act[i, j], pred_act[i, j].long()] += 1\n",
    "\n",
    "    \n",
    "\n",
    "print(f'Loss: {total_loss / obs_count}, Correct: {total_correct / obs_count}, Correct On Ground: {correct_on_ground / total_on_ground}, On Ground: {total_on_ground / obs_count}')\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "print((conf_mtx).cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLGym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "baa0d24347c96f08397175d5f5df5429dcdfcaeab02cd215c26c77f2399e651c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
