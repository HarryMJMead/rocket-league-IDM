{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import wandb\n",
    "import os\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "from lib.data import EpisodeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, obs_size=21, obs_width=2, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.input_size = obs_size*obs_width*2\n",
    "\n",
    "        self.linearNN = nn.Sequential(\n",
    "              nn.Linear(self.input_size, hidden_size),\n",
    "              nn.ReLU(),\n",
    "            #   nn.Linear(hidden_size, hidden_size),\n",
    "            #   nn.ReLU(),\n",
    "            #   nn.Linear(hidden_size, hidden_size),\n",
    "            #   nn.ReLU(),\n",
    "            #   nn.Linear(hidden_size, hidden_size),\n",
    "            #   nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        self.action = nn.Sequential(\n",
    "              nn.Linear(hidden_size, hidden_size),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(hidden_size, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self,seq):\n",
    "        pred = self.linearNN(seq.reshape(-1, self.input_size))\n",
    "\n",
    "        action = F.log_softmax(self.action(pred), dim=1)\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 5\n",
    "OBS_SIZE = 46\n",
    "HIDDEN_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Episode Data\n",
      "Finished Loading Episode Data\n",
      "311700\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH_1 = '/home/bdemoss/Desktop/RL IDM/Episode Data/Random Data/30 TPS/3v3 Train'\n",
    "TRAIN_PATH_2 = '/home/bdemoss/Desktop/RL IDM/Episode Data/Nexto Data/30 TPS/3v3 Train'\n",
    "\n",
    "train_dataset = EpisodeDataset([TRAIN_PATH_1, TRAIN_PATH_2], width=WIDTH, include_change=True, corrupt=True)\n",
    "\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data_Loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ConvNet(obs_size=OBS_SIZE, obs_width=WIDTH, conv_number=10, hidden_size=HIDDEN_SIZE)\n",
    "model = FullyConnected(obs_size=OBS_SIZE, obs_width=WIDTH, hidden_size=HIDDEN_SIZE)\n",
    "\n",
    "gpumodel = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gpumodel.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpumodel.load_state_dict(torch.load('trained_networks/fc3_all_512x4_w_change_corrupt_w_og.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharrymead\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/bdemoss/Desktop/RL IDM/rocket-league-IDM/wandb/run-20230131_151728-wvmai3k7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/harrymead/Inverse%20Dynamics%20Model/runs/wvmai3k7\" target=\"_blank\">prosperous-ox-112</a></strong> to <a href=\"https://wandb.ai/harrymead/Inverse%20Dynamics%20Model\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/harrymead/Inverse%20Dynamics%20Model\" target=\"_blank\">https://wandb.ai/harrymead/Inverse%20Dynamics%20Model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/harrymead/Inverse%20Dynamics%20Model/runs/wvmai3k7\" target=\"_blank\">https://wandb.ai/harrymead/Inverse%20Dynamics%20Model/runs/wvmai3k7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"Inverse Dynamics Model\", entity=\"harrymead\")\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.0001,\n",
    "  \"epochs\": 10,\n",
    "  \"batch_size\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.6072411048334925, Correct: 0.7321323752403259\n",
      "Epoch 1 - Loss: 0.4171096659805904, Correct: 0.8365329504013062\n",
      "Epoch 1 - Loss: 0.3467875951761963, Correct: 0.8728979825973511\n",
      "Epoch 1 - Loss: 0.3056502761200334, Correct: 0.8908929228782654\n",
      "Epoch 1 - Loss: 0.28382529862504957, Correct: 0.901045560836792\n",
      "Epoch 1 - Loss: 0.26493435898601625, Correct: 0.9108210206031799\n",
      "Epoch 1 - Loss: 0.24457381846709383, Correct: 0.9184700846672058\n",
      "Epoch 1 - Loss: 0.23058932912726773, Correct: 0.9241077899932861\n",
      "Epoch 1 - Loss: 0.2249167845145205, Correct: 0.9262722134590149\n",
      "Epoch 1 - Loss: 0.21473574039917992, Correct: 0.9305453300476074\n",
      "Epoch 1 - Loss: 0.21778084393104863, Correct: 0.9305371046066284\n",
      "Epoch 1 - Loss: 0.1996282979432869, Correct: 0.9338614344596863\n",
      "Epoch 1 - Loss: 0.19461585618716995, Correct: 0.9362353682518005\n",
      "Epoch 1 - Loss: 0.19523326732974053, Correct: 0.9363150000572205\n",
      "Epoch 1 - Loss: 0.1867398199871154, Correct: 0.9381107091903687\n",
      "Epoch 1 - Loss: 0.17730196065362866, Correct: 0.9409824013710022\n",
      "Epoch 1 - Loss: 0.17998730239652294, Correct: 0.940233588218689\n",
      "Epoch 1 - Loss: 0.1668875638873579, Correct: 0.9449725151062012\n",
      "Epoch 1 - Loss: 0.17267551862259628, Correct: 0.9414912462234497\n",
      "Epoch 1 - Loss: 0.17411832865060187, Correct: 0.9407737851142883\n",
      "Epoch 1 - Loss: 0.16973468390090382, Correct: 0.9425909519195557\n",
      "Epoch 1 - Loss: 0.17046838984384663, Correct: 0.943114161491394\n",
      "Epoch 1 - Loss: 0.16672232024747013, Correct: 0.9440761208534241\n",
      "Epoch 1 - Loss: 0.1653078701085328, Correct: 0.9430698156356812\n",
      "Epoch 1 - Loss: 0.16204972808942814, Correct: 0.9440193176269531\n",
      "Epoch 1 - Loss: 0.15897320941232945, Correct: 0.9462178349494934\n",
      "Epoch 1 - Loss: 0.15660715569237085, Correct: 0.9470123052597046\n",
      "Epoch 1 - Loss: 0.1595138265761532, Correct: 0.9471927881240845\n",
      "Epoch 1 - Loss: 0.1543032547227659, Correct: 0.9468570947647095\n",
      "Epoch 1 - Loss: 0.14926497382038004, Correct: 0.9479934573173523\n",
      "Epoch 1 - Loss: 0.1606213372488273, Correct: 0.9458069205284119\n",
      "Epoch 1 - Loss: 0.15014377139246696, Correct: 0.9484082460403442\n",
      "Epoch 1 - Loss: 0.1533907441342636, Correct: 0.9472544193267822\n",
      "Epoch 1 - Loss: 0.1483898409346785, Correct: 0.9491550326347351\n",
      "Epoch 1 - Loss: 0.1522938582302418, Correct: 0.9484087228775024\n",
      "Epoch 1 - Loss: 0.15348892222138974, Correct: 0.946837842464447\n",
      "Epoch 1 - Loss: 0.1403315130859081, Correct: 0.9499488472938538\n",
      "Epoch 1 - Loss: 0.14359264645169012, Correct: 0.9501475095748901\n",
      "Epoch 1 - Loss: 0.13971862868558485, Correct: 0.9503810405731201\n",
      "Epoch 1 - Loss: 0.13519515429303308, Correct: 0.9529644846916199\n",
      "Epoch 1 - Loss: 0.148726089458675, Correct: 0.9490686058998108\n",
      "Epoch 1 - Loss: 0.14675769243813847, Correct: 0.9485856890678406\n",
      "Epoch 1 - Loss: 0.14346347834796191, Correct: 0.9491991996765137\n",
      "Epoch 1 - Loss: 0.1352348733539615, Correct: 0.9522542357444763\n",
      "Epoch 1 - Loss: 0.1437460064334517, Correct: 0.9493294358253479\n",
      "Epoch 1 - Loss: 0.14533142809228225, Correct: 0.9486794471740723\n",
      "Epoch 1 - Loss: 0.14039755084788844, Correct: 0.9505792260169983\n",
      "Epoch 1 - Loss: 0.13289700051457765, Correct: 0.9527375102043152\n",
      "Epoch 1 - Loss: 0.13639581064373607, Correct: 0.9511839747428894\n",
      "Epoch 1 - Loss: 0.1336897625001679, Correct: 0.9526352882385254\n",
      "Epoch 1 - Loss: 0.13316697826410537, Correct: 0.9530016779899597\n",
      "Epoch 1 - Loss: 0.1363439151557215, Correct: 0.9514858722686768\n",
      "Epoch 1 - Loss: 0.13338898078935427, Correct: 0.9533040523529053\n",
      "Epoch 1 - Loss: 0.13578722091810771, Correct: 0.9512080550193787\n",
      "Epoch 1 - Loss: 0.13200332249434765, Correct: 0.9524307250976562\n",
      "Epoch 1 - Loss: 0.13661271603458172, Correct: 0.9517109990119934\n",
      "Epoch 1 - Loss: 0.12968213814948412, Correct: 0.953568160533905\n",
      "Epoch 1 - Loss: 0.1326104193284902, Correct: 0.9524656534194946\n",
      "Epoch 1 - Loss: 0.1298094112076576, Correct: 0.954870879650116\n",
      "Epoch 1 - Loss: 0.13222990794626902, Correct: 0.9533591270446777\n",
      "Epoch 1 - Loss: 0.13068594175219836, Correct: 0.9529714584350586\n",
      "Epoch 1 - Loss: 0.13368429907514667, Correct: 0.9515852928161621\n",
      "Epoch 1 - Loss: 0.1298178718562478, Correct: 0.9534304141998291\n",
      "Epoch 1 - Loss: 0.1364266659035795, Correct: 0.9522193670272827\n",
      "Epoch 1 - Loss: 0.12498514591943459, Correct: 0.9547867774963379\n",
      "Epoch 1 - Loss: 0.1281336671107319, Correct: 0.9547266960144043\n",
      "Epoch 1 - Loss: 0.1192583936017486, Correct: 0.9568390846252441\n",
      "Epoch 1 - Loss: 0.13098873666003277, Correct: 0.9541580677032471\n",
      "Epoch 1 - Loss: 0.12225773555578094, Correct: 0.9560837745666504\n",
      "Epoch 1 - Loss: 0.12374618425714508, Correct: 0.9558283686637878\n",
      "Epoch 1 - Loss: 0.13355716162886722, Correct: 0.9512218832969666\n",
      "Epoch 1 - Loss: 0.13609661099087506, Correct: 0.9520294666290283\n",
      "Epoch 1 - Loss: 0.12890234703432654, Correct: 0.9549774527549744\n",
      "Epoch 1 - Loss: 0.12637858486477485, Correct: 0.9542383551597595\n",
      "Epoch 1 - Loss: 0.11953624860520334, Correct: 0.9564467072486877\n",
      "Epoch 1 - Loss: 0.1228495731961215, Correct: 0.9556284546852112\n",
      "Epoch 1 - Loss: 0.12834161996479412, Correct: 0.9557570815086365\n",
      "Epoch 1 - Loss: 0.1251600769738852, Correct: 0.9550718069076538\n",
      "Epoch 1 - Loss: 0.12130091138135189, Correct: 0.9559441208839417\n",
      "Epoch 1 - Loss: 0.12960987832887397, Correct: 0.9544026255607605\n",
      "Epoch 1 - Loss: 0.12596957754774205, Correct: 0.9547263383865356\n",
      "Epoch 1 - Loss: 0.12402990552748115, Correct: 0.9545736908912659\n",
      "Epoch 1 - Loss: 0.1219326603464329, Correct: 0.9559371471405029\n",
      "Epoch 1 - Loss: 0.12013964566423366, Correct: 0.9565933346748352\n",
      "Epoch 1 - Loss: 0.11859309224128993, Correct: 0.9566484093666077\n",
      "Epoch 1 - Loss: 0.12121279244592915, Correct: 0.9572848081588745\n",
      "Epoch 1 - Loss: 0.12179222352077171, Correct: 0.9559313654899597\n",
      "Epoch 1 - Loss: 0.12092769814276917, Correct: 0.9558231830596924\n",
      "Epoch 1 - Loss: 0.12171170191478786, Correct: 0.9559314250946045\n",
      "Epoch 1 - Loss: 0.1235546985195049, Correct: 0.9553918838500977\n",
      "Epoch 1 - Loss: 0.11663886108077111, Correct: 0.9577317237854004\n",
      "Epoch 1 - Loss: 0.12160357038999785, Correct: 0.9549154043197632\n",
      "Epoch 1 - Loss: 0.11518383617214312, Correct: 0.9580227732658386\n",
      "Epoch 1 - Loss: 0.11571447697601336, Correct: 0.9575396776199341\n",
      "Epoch 1 - Loss: 0.1239702299970282, Correct: 0.9561939239501953\n",
      "Epoch 1 - Loss: 0.11513034860848294, Correct: 0.958169162273407\n",
      "Epoch 1 - Loss: 0.11681250328126228, Correct: 0.9579612612724304\n",
      "Epoch 1 - Loss: 0.1167749390390801, Correct: 0.9577203989028931\n",
      "Epoch 1 - Loss: 0.11703953282869613, Correct: 0.9573290944099426\n",
      "Epoch 1 - Loss: 0.11395992516380464, Correct: 0.9585949778556824\n",
      "Epoch 1 - Loss: 0.11978432603493873, Correct: 0.9558353424072266\n",
      "Epoch 1 - Loss: 0.11487575777641697, Correct: 0.9579596519470215\n",
      "Epoch 1 - Loss: 0.1247708849439597, Correct: 0.9560757875442505\n",
      "Epoch 1 - Loss: 0.11607026424065654, Correct: 0.9576932191848755\n",
      "Epoch 1 - Loss: 0.1181578834927416, Correct: 0.9565145969390869\n",
      "Epoch 1 - Loss: 0.12183707874597399, Correct: 0.9570438861846924\n",
      "Epoch 1 - Loss: 0.11246769866173807, Correct: 0.9588716626167297\n",
      "Epoch 1 - Loss: 0.11422853267442755, Correct: 0.9582843780517578\n",
      "Epoch 1 - Loss: 0.11418739976162447, Correct: 0.9585954546928406\n",
      "Epoch 1 - Loss: 0.11258317410874524, Correct: 0.9584516286849976\n",
      "Epoch 1 - Loss: 0.11889392724317593, Correct: 0.9564794301986694\n",
      "Epoch 1 - Loss: 0.11710777132200126, Correct: 0.9557785987854004\n",
      "Epoch 1 - Loss: 0.11453753856050337, Correct: 0.9579123258590698\n",
      "Epoch 1 - Loss: 0.11279770871282961, Correct: 0.9584897756576538\n",
      "Epoch 1 - Loss: 0.11198804811266355, Correct: 0.9591002464294434\n",
      "Epoch 1 - Loss: 0.11648245657322306, Correct: 0.957909882068634\n",
      "Epoch 1 - Loss: 0.1171498606828115, Correct: 0.9569355845451355\n",
      "Epoch 1 - Loss: 0.11182299559887579, Correct: 0.9591879844665527\n",
      "Epoch 1 - Loss: 0.11452231741227797, Correct: 0.9581806063652039\n",
      "Epoch 1 - Loss: 0.10944661597703559, Correct: 0.9600905776023865\n",
      "Epoch 1 - Loss: 0.12009031870802188, Correct: 0.9564945101737976\n",
      "Epoch 1 - Loss: 0.11239647787202227, Correct: 0.958683967590332\n",
      "Epoch 1 - Loss: 0.11079557593474107, Correct: 0.959230363368988\n",
      "Epoch 1 - Loss: 0.11149588125455949, Correct: 0.9594984650611877\n",
      "Epoch 1 - Loss: 0.10682488530568839, Correct: 0.9604699611663818\n",
      "Epoch 1 - Loss: 0.11016449869583864, Correct: 0.9593368768692017\n",
      "Epoch 1 - Loss: 0.11090911473923255, Correct: 0.9582870006561279\n",
      "Epoch 1 - Loss: 0.11112954350368055, Correct: 0.9585863947868347\n",
      "Epoch 1 - Loss: 0.10523943759650178, Correct: 0.961561918258667\n",
      "Epoch 1 - Loss: 0.11181642119483953, Correct: 0.9590123891830444\n",
      "Epoch 1 - Loss: 0.10412698993741004, Correct: 0.9617890119552612\n",
      "Epoch 1 - Loss: 0.1117389059139969, Correct: 0.9590318202972412\n",
      "Epoch 1 - Loss: 0.1135405568152968, Correct: 0.9573975801467896\n",
      "Epoch 1 - Loss: 0.10726359264539956, Correct: 0.9601011276245117\n",
      "Epoch 1 - Loss: 0.11718422463340182, Correct: 0.9574359655380249\n",
      "Epoch 1 - Loss: 0.10944920605997085, Correct: 0.9597412347793579\n",
      "Epoch 1 - Loss: 0.10926484450260561, Correct: 0.9589343070983887\n",
      "Epoch 1 - Loss: 0.11092761586369554, Correct: 0.9603747725486755\n",
      "Epoch 1 - Loss: 0.11005647685384078, Correct: 0.9592469334602356\n",
      "Epoch 1 - Loss: 0.11214919640882025, Correct: 0.9587856531143188\n",
      "Epoch 1 - Loss: 0.10957048932895078, Correct: 0.9595125317573547\n",
      "Epoch 1 - Loss: 0.10880869331358563, Correct: 0.9591838717460632\n",
      "Epoch 1 - Loss: 0.11404021124848455, Correct: 0.9580429792404175\n",
      "Epoch 1 - Loss: 0.10652734977130777, Correct: 0.9599938988685608\n",
      "Epoch 1 - Loss: 0.11094564398858867, Correct: 0.9593374729156494\n",
      "Epoch 1 - Loss: 0.11035684947391433, Correct: 0.9588794112205505\n",
      "Epoch 1 - Loss: 0.11127317904049043, Correct: 0.9586285352706909\n",
      "Epoch 1 - Loss: 0.11054105874176945, Correct: 0.9600351452827454\n",
      "Epoch 1 - Loss: 0.10464483119226374, Correct: 0.9613887071609497\n",
      "Epoch 1 - Loss: 0.10692672933026363, Correct: 0.9603345990180969\n",
      "Epoch 1 - Loss: 0.10615977049520213, Correct: 0.9609017968177795\n",
      "Epoch 1 - Loss: 0.1076963309672236, Correct: 0.9592089653015137\n",
      "Epoch 1 - Loss: 0.10685356877314946, Correct: 0.9605043530464172\n",
      "Epoch 1 - Loss: 0.10821440360874744, Correct: 0.9597511887550354\n",
      "Epoch 1 - Loss: 0.11183353434620392, Correct: 0.9584330320358276\n",
      "Epoch 1 - Loss: 0.10671189455264672, Correct: 0.9607175588607788\n",
      "Epoch 1 - Loss: 0.11029228013851332, Correct: 0.9594271183013916\n",
      "Epoch 1 - Loss: 0.10903651995812441, Correct: 0.9596844911575317\n",
      "Epoch 1 - Loss: 0.1067534058695737, Correct: 0.9602586030960083\n",
      "Epoch 1 - Loss: 0.11105332030182158, Correct: 0.9590468406677246\n",
      "Epoch 1 - Loss: 0.10884441496310247, Correct: 0.960299551486969\n",
      "Epoch 1 - Loss: 0.11047594810464047, Correct: 0.9583784937858582\n",
      "Epoch 1 - Loss: 0.10671019406375462, Correct: 0.9605607390403748\n",
      "Epoch 1 - Loss: 0.10244580441522871, Correct: 0.9616390466690063\n",
      "Epoch 1 - Loss: 0.10887768963875046, Correct: 0.9593157768249512\n",
      "Epoch 1 - Loss: 0.10794374241920332, Correct: 0.9602497816085815\n",
      "Epoch 1 - Loss: 0.10591848056000339, Correct: 0.9611848592758179\n",
      "Epoch 1 - Loss: 0.1077915027800972, Correct: 0.9594895243644714\n",
      "Epoch 1 - Loss: 0.11154590229122063, Correct: 0.9591294527053833\n",
      "Epoch 1 - Loss: 0.10896639659833732, Correct: 0.9588282704353333\n",
      "Epoch 1 - Loss: 0.10915389401194242, Correct: 0.9589751958847046\n",
      "Epoch 1 - Loss: 0.1091100862938306, Correct: 0.959134042263031\n",
      "Epoch 1 - Loss: 0.11035511001572815, Correct: 0.9589617848396301\n",
      "Epoch 1 - Loss: 0.10476873942709845, Correct: 0.9615257978439331\n",
      "Epoch 1 - Loss: 0.10814806385383136, Correct: 0.9594590663909912\n",
      "Epoch 1 - Loss: 0.10915458483622152, Correct: 0.9589499235153198\n",
      "Epoch 1 - Loss: 0.10924235537850593, Correct: 0.9601328372955322\n",
      "Epoch 1 - Loss: 0.11190563833181842, Correct: 0.9583973288536072\n",
      "Epoch 1 - Loss: 0.10383822806746291, Correct: 0.9610655903816223\n",
      "Epoch 1 - Loss: 0.10710558670051643, Correct: 0.9594606757164001\n",
      "Epoch 1 - Loss: 0.10730912103190293, Correct: 0.9596834778785706\n",
      "Epoch 1 - Loss: 0.10315141831747665, Correct: 0.9618825912475586\n",
      "Epoch 1 - Loss: 0.104234197012907, Correct: 0.959943413734436\n",
      "Epoch 1 - Loss: 0.10312016732192779, Correct: 0.9610006213188171\n",
      "Epoch 1 - Loss: 0.11141455458082926, Correct: 0.9571106433868408\n",
      "Epoch 1 - Loss: 0.10462560777572849, Correct: 0.960949718952179\n",
      "Epoch 1 - Loss: 0.09967023096672877, Correct: 0.9620252251625061\n",
      "Epoch 1 - Loss: 0.10424057866208351, Correct: 0.960628092288971\n",
      "Epoch 1 - Loss: 0.10399056586011159, Correct: 0.9614313244819641\n",
      "Epoch 1 - Loss: 0.10623550866413038, Correct: 0.9605144262313843\n",
      "Epoch 1 - Loss: 0.10430727924068474, Correct: 0.9607877731323242\n",
      "Epoch 1 - Loss: 0.11335722263779899, Correct: 0.958441436290741\n",
      "Epoch 1 - Loss: 0.09883470361133435, Correct: 0.9631325602531433\n",
      "Epoch 1 - Loss: 0.10526866130849354, Correct: 0.9604718089103699\n",
      "Epoch 1 - Loss: 0.10448842559866835, Correct: 0.9613682627677917\n",
      "Epoch 1 - Loss: 0.10205255676171279, Correct: 0.9619659781455994\n",
      "Epoch 1 - Loss: 0.09878064336150626, Correct: 0.962094783782959\n",
      "Epoch 1 - Loss: 0.10003695938117899, Correct: 0.9626635313034058\n",
      "Epoch 1 - Loss: 0.10552772048805184, Correct: 0.960076630115509\n",
      "Epoch 1 - Loss: 0.10262924594935276, Correct: 0.9608399271965027\n",
      "Epoch 1 - Loss: 0.10279827053343403, Correct: 0.9614701867103577\n",
      "Epoch 1 - Loss: 0.10239051457970595, Correct: 0.9616988301277161\n",
      "Epoch 1 - Loss: 0.10183848281436435, Correct: 0.9624389410018921\n",
      "Epoch 1 - Loss: 0.10185227293479383, Correct: 0.9614500403404236\n",
      "Epoch 1 - Loss: 0.10046112621767575, Correct: 0.9620242118835449\n",
      "Epoch 1 - Loss: 0.10796795165104618, Correct: 0.9603042006492615\n",
      "Epoch 1 - Loss: 0.1085461353921054, Correct: 0.9597702026367188\n",
      "Epoch 1 - Loss: 0.10609282940289433, Correct: 0.9598002433776855\n",
      "Epoch 1 - Loss: 0.09974920412861933, Correct: 0.9619859457015991\n",
      "Epoch 1 - Loss: 0.10145438565057911, Correct: 0.9621488451957703\n",
      "Epoch 1 - Loss: 0.10203480768586769, Correct: 0.9627450704574585\n",
      "Epoch 1 - Loss: 0.10402514042065858, Correct: 0.9608640670776367\n",
      "Epoch 1 - Loss: 0.1145166972780878, Correct: 0.9575884938240051\n",
      "Epoch 1 - Loss: 0.10200870399086857, Correct: 0.9612720608711243\n",
      "Epoch 1 - Loss: 0.10163898168090184, Correct: 0.9620444774627686\n",
      "Epoch 1 - Loss: 0.1093802940522148, Correct: 0.9579960703849792\n",
      "Epoch 1 - Loss: 0.09922007222205267, Correct: 0.962290346622467\n",
      "Epoch 1 - Loss: 0.09927377331895737, Correct: 0.963104248046875\n",
      "Epoch 1 - Loss: 0.0991785047797915, Correct: 0.9629653692245483\n",
      "Epoch 1 - Loss: 0.09906231427775418, Correct: 0.9624624848365784\n",
      "Epoch 1 - Loss: 0.10266165679556807, Correct: 0.9616063237190247\n",
      "Epoch 1 - Loss: 0.10150646848656722, Correct: 0.9621809124946594\n",
      "Epoch 1 - Loss: 0.10687314486166768, Correct: 0.9599613547325134\n",
      "Epoch 1 - Loss: 0.1016186878451309, Correct: 0.9611204862594604\n",
      "Epoch 1 - Loss: 0.10124785969855826, Correct: 0.9617276787757874\n",
      "Epoch 1 - Loss: 0.1035907176188546, Correct: 0.9600894451141357\n",
      "Epoch 1 - Loss: 0.1021426430178894, Correct: 0.9612400531768799\n",
      "Epoch 1 - Loss: 0.10389784239631956, Correct: 0.9613216519355774\n",
      "Epoch 1 - Loss: 0.10420717184145807, Correct: 0.961633563041687\n",
      "Epoch 1 - Loss: 0.10258317528331455, Correct: 0.961273193359375\n",
      "Epoch 1 - Loss: 0.10428539525465065, Correct: 0.9605721831321716\n",
      "Epoch 1 - Loss: 0.09995080004975301, Correct: 0.96286541223526\n",
      "Epoch 1 - Loss: 0.10202178338148814, Correct: 0.9608587622642517\n",
      "Epoch 1 - Loss: 0.10099171452737245, Correct: 0.9617520570755005\n",
      "Epoch 1 - Loss: 0.10520946206379159, Correct: 0.9606244564056396\n",
      "Epoch 1 - Loss: 0.09695914451399285, Correct: 0.963459849357605\n",
      "Epoch 1 - Loss: 0.09961093705181188, Correct: 0.9629106521606445\n",
      "Epoch 1 - Loss: 0.10099101279194009, Correct: 0.9618197083473206\n",
      "Epoch 1 - Loss: 0.09746281033396455, Correct: 0.9629964828491211\n",
      "Epoch 1 - Loss: 0.09493646746801201, Correct: 0.964401125907898\n",
      "Epoch 1 - Loss: 0.09857991402909455, Correct: 0.9626808166503906\n",
      "Epoch 1 - Loss: 0.10029410155048513, Correct: 0.961732804775238\n",
      "Epoch 1 - Loss: 0.10298416793513156, Correct: 0.9607754945755005\n",
      "Epoch 1 - Loss: 0.09919212937124301, Correct: 0.9629601836204529\n",
      "Epoch 1 - Loss: 0.09871371206577445, Correct: 0.9627969264984131\n",
      "Epoch 1 - Loss: 0.1002157870919783, Correct: 0.9629915356636047\n",
      "Epoch 1 - Loss: 0.09753978810069175, Correct: 0.9631362557411194\n",
      "Epoch 1 - Loss: 0.09522149013832769, Correct: 0.9641796946525574\n",
      "Epoch 1 - Loss: 0.10649881130165553, Correct: 0.9596272706985474\n",
      "Epoch 1 - Loss: 0.10097272758059161, Correct: 0.9620887041091919\n",
      "Epoch 1 - Loss: 0.10209960452703114, Correct: 0.9613293409347534\n",
      "Epoch 1 - Loss: 0.10204431638750172, Correct: 0.9606248140335083\n",
      "Epoch 1 - Loss: 0.10089402839215635, Correct: 0.9615828394889832\n",
      "Epoch 1 - Loss: 0.10353370757218806, Correct: 0.9613293409347534\n",
      "Epoch 1 - Loss: 0.09910639691323551, Correct: 0.9625033140182495\n",
      "Epoch 1 - Loss: 0.10056590295620363, Correct: 0.9623663425445557\n",
      "Epoch 1 - Loss: 0.10160034046769284, Correct: 0.9615184664726257\n",
      "Epoch 1 - Loss: 0.09615509212129643, Correct: 0.964160144329071\n",
      "Epoch 1 - Loss: 0.10363750243947434, Correct: 0.9607057571411133\n",
      "Epoch 1 - Loss: 0.10153666957650695, Correct: 0.9625034928321838\n",
      "Epoch 1 - Loss: 0.09866241478498076, Correct: 0.9622898697853088\n",
      "Epoch 1 - Loss: 0.09710622317139929, Correct: 0.9631276726722717\n",
      "Epoch 1 - Loss: 0.10083771549610522, Correct: 0.9623454809188843\n",
      "Epoch 1 - Loss: 0.10177163824859581, Correct: 0.9621383547782898\n",
      "Epoch 1 - Loss: 0.1065629561091716, Correct: 0.9600535035133362\n",
      "Epoch 1 - Loss: 0.09877295849684331, Correct: 0.9626461863517761\n",
      "Epoch 1 - Loss: 0.10425217952443695, Correct: 0.9609641432762146\n",
      "Epoch 1 - Loss: 0.09947263194322824, Correct: 0.962295651435852\n",
      "Epoch 1 - Loss: 0.09606256339478614, Correct: 0.9634637832641602\n",
      "Epoch 1 - Loss: 0.09839167380644884, Correct: 0.9625725150108337\n",
      "Epoch 1 - Loss: 0.09897428728039692, Correct: 0.962324321269989\n",
      "Epoch 1 - Loss: 0.09002504067851955, Correct: 0.9660754203796387\n",
      "Epoch 1 - Loss: 0.09556653413506085, Correct: 0.9634320735931396\n",
      "Epoch 1 - Loss: 0.09546348988515607, Correct: 0.963989794254303\n",
      "Epoch 1 - Loss: 0.10274070618403065, Correct: 0.9615916013717651\n",
      "Epoch 1 - Loss: 0.10081885087247268, Correct: 0.9622092843055725\n",
      "Epoch 1 - Loss: 0.10198328880872022, Correct: 0.9622553586959839\n",
      "Epoch 1 - Loss: 0.10463437758270597, Correct: 0.960739016532898\n",
      "Epoch 1 - Loss: 0.09731162852659947, Correct: 0.9625419974327087\n",
      "Epoch 1 - Loss: 0.09485888827893338, Correct: 0.9641945958137512\n",
      "Epoch 1 - Loss: 0.10472681365550662, Correct: 0.9616959691047668\n",
      "Epoch 1 - Loss: 0.10123001960786708, Correct: 0.9618476629257202\n",
      "Epoch 1 - Loss: 0.09709247702986802, Correct: 0.9633017778396606\n",
      "Epoch 1 - Loss: 0.09812599498467023, Correct: 0.9624462723731995\n",
      "Epoch 1 - Loss: 0.10156841386655194, Correct: 0.9618271589279175\n",
      "Epoch 1 - Loss: 0.09848636785251624, Correct: 0.9626210331916809\n",
      "Epoch 1 - Loss: 0.10390545554180733, Correct: 0.9608511328697205\n",
      "Epoch 1 - Loss: 0.09298379991096793, Correct: 0.9652474522590637\n",
      "Epoch 1 - Loss: 0.09657737801388624, Correct: 0.9632346034049988\n",
      "Epoch 1 - Loss: 0.10279449415449342, Correct: 0.9609792232513428\n",
      "Epoch 1 - Loss: 0.09738479840310792, Correct: 0.9633278250694275\n",
      "Epoch 1 - Loss: 0.09811175126706914, Correct: 0.9635178446769714\n",
      "Epoch 1 - Loss: 0.0995892202150436, Correct: 0.9625291228294373\n",
      "Epoch 1 - Loss: 0.10613879487874707, Correct: 0.9602985978126526\n",
      "Epoch 1 - Loss: 0.09768584929784793, Correct: 0.9631724953651428\n",
      "Epoch 1 - Loss: 0.09880768992930986, Correct: 0.9620004296302795\n",
      "Epoch 1 - Loss: 0.100807743958462, Correct: 0.9615144729614258\n",
      "Epoch 1 - Loss: 0.09991301803169586, Correct: 0.9617710709571838\n",
      "Epoch 1 - Loss: 0.10008129849791783, Correct: 0.9621911644935608\n",
      "Epoch 1 - Loss: 0.09890676250375102, Correct: 0.9626898169517517\n",
      "Epoch 1 - Loss: 0.09788819526948113, Correct: 0.9635194540023804\n",
      "Epoch 1 - Loss: 0.10545239100543327, Correct: 0.9606345891952515\n",
      "Epoch 1 - Loss: 0.09307255437612541, Correct: 0.9648858904838562\n",
      "Epoch 1 - Loss: 0.10044783924192492, Correct: 0.9622536301612854\n",
      "Epoch 1 - Loss: 0.09800251174682799, Correct: 0.9626574516296387\n",
      "Epoch 1 - Loss: 0.09908255458387943, Correct: 0.9614159464836121\n",
      "Epoch 1 - Loss: 0.0978986763771057, Correct: 0.9626786708831787\n",
      "Epoch 1 - Loss: 0.10412128917621627, Correct: 0.9619643688201904\n",
      "Epoch 1 - Loss: 0.09699089557020188, Correct: 0.9629404544830322\n",
      "Epoch 1 - Loss: 0.10610730019207963, Correct: 0.9606448411941528\n",
      "Epoch 1 - Loss: 0.09619080316471623, Correct: 0.9631588459014893\n",
      "Epoch 2 - Loss: 0.09788814135049578, Correct: 0.9628130197525024\n",
      "Epoch 2 - Loss: 0.09570993158703596, Correct: 0.9631701111793518\n",
      "Epoch 2 - Loss: 0.09753764425893367, Correct: 0.9636254906654358\n",
      "Epoch 2 - Loss: 0.09880264428780444, Correct: 0.9629750847816467\n",
      "Epoch 2 - Loss: 0.10121648779138266, Correct: 0.9618414640426636\n",
      "Epoch 2 - Loss: 0.0918204781997781, Correct: 0.9655859470367432\n",
      "Epoch 2 - Loss: 0.09966675846130833, Correct: 0.9609881639480591\n",
      "Epoch 2 - Loss: 0.09310917999613195, Correct: 0.9640812277793884\n",
      "Epoch 2 - Loss: 0.09994315846484533, Correct: 0.9622575044631958\n",
      "Epoch 2 - Loss: 0.09537310417346277, Correct: 0.9635473489761353\n",
      "Epoch 2 - Loss: 0.09754394952978362, Correct: 0.963398277759552\n",
      "Epoch 2 - Loss: 0.10163896780575907, Correct: 0.9617148637771606\n",
      "Epoch 2 - Loss: 0.09640835545497776, Correct: 0.9635464549064636\n",
      "Epoch 2 - Loss: 0.09618538817016148, Correct: 0.9638797044754028\n",
      "Epoch 2 - Loss: 0.10353862858229641, Correct: 0.9605110287666321\n",
      "Epoch 2 - Loss: 0.09719105354012456, Correct: 0.9629075527191162\n",
      "Epoch 2 - Loss: 0.09704123711667885, Correct: 0.9630127549171448\n",
      "Epoch 2 - Loss: 0.0948567083822428, Correct: 0.9636864066123962\n",
      "Epoch 2 - Loss: 0.09483296952456396, Correct: 0.9633894562721252\n",
      "Epoch 2 - Loss: 0.09729712039445758, Correct: 0.9628005027770996\n",
      "Epoch 2 - Loss: 0.09430954387993845, Correct: 0.9640990495681763\n",
      "Epoch 2 - Loss: 0.09266257408109209, Correct: 0.9647771120071411\n",
      "Epoch 2 - Loss: 0.09823861888582049, Correct: 0.9633532166481018\n",
      "Epoch 2 - Loss: 0.09623546969047839, Correct: 0.9627916216850281\n",
      "Epoch 2 - Loss: 0.09597532950283216, Correct: 0.9636831283569336\n",
      "Epoch 2 - Loss: 0.1021987886370226, Correct: 0.9602403044700623\n",
      "Epoch 2 - Loss: 0.09378545818032447, Correct: 0.9641616344451904\n",
      "Epoch 2 - Loss: 0.09599809492093363, Correct: 0.9638328552246094\n",
      "Epoch 2 - Loss: 0.0981378552806872, Correct: 0.9622634053230286\n",
      "Epoch 2 - Loss: 0.09790030181664389, Correct: 0.9624897241592407\n",
      "Epoch 2 - Loss: 0.09686806667888424, Correct: 0.9630675315856934\n",
      "Epoch 2 - Loss: 0.09542911739314522, Correct: 0.9635693430900574\n",
      "Epoch 2 - Loss: 0.10288223453901915, Correct: 0.9620694518089294\n",
      "Epoch 2 - Loss: 0.10162974172834006, Correct: 0.9613986015319824\n",
      "Epoch 2 - Loss: 0.09511519448524822, Correct: 0.9638569951057434\n",
      "Epoch 2 - Loss: 0.0972926851123303, Correct: 0.9625759720802307\n",
      "Epoch 2 - Loss: 0.09683262277421424, Correct: 0.9633155465126038\n",
      "Epoch 2 - Loss: 0.09507203507373746, Correct: 0.9641259908676147\n",
      "Epoch 2 - Loss: 0.10471258175159755, Correct: 0.9606155157089233\n",
      "Epoch 2 - Loss: 0.10053159938828493, Correct: 0.9615007042884827\n",
      "Epoch 2 - Loss: 0.09578645917051647, Correct: 0.9627472758293152\n",
      "Epoch 2 - Loss: 0.09304365597919545, Correct: 0.9646282196044922\n",
      "Epoch 2 - Loss: 0.09446391695454823, Correct: 0.9636960625648499\n",
      "Epoch 2 - Loss: 0.09203518176166942, Correct: 0.9646559357643127\n",
      "Epoch 2 - Loss: 0.09495535941020083, Correct: 0.9632226228713989\n",
      "Epoch 2 - Loss: 0.0973368525318313, Correct: 0.9634811878204346\n",
      "Epoch 2 - Loss: 0.09545411647926252, Correct: 0.9633821845054626\n",
      "Epoch 2 - Loss: 0.09481776397283338, Correct: 0.9637281894683838\n",
      "Epoch 2 - Loss: 0.09132349074713245, Correct: 0.9656715393066406\n",
      "Epoch 2 - Loss: 0.09697682202566404, Correct: 0.9616150259971619\n",
      "Epoch 2 - Loss: 0.08959965501285347, Correct: 0.9658575654029846\n",
      "Epoch 2 - Loss: 0.09331591616497197, Correct: 0.964215874671936\n",
      "Epoch 2 - Loss: 0.09951707203481157, Correct: 0.962440550327301\n",
      "Epoch 2 - Loss: 0.09984644884452051, Correct: 0.9620693922042847\n",
      "Epoch 2 - Loss: 0.09672646397390063, Correct: 0.9631531834602356\n",
      "Epoch 2 - Loss: 0.09331792761639705, Correct: 0.963922917842865\n",
      "Epoch 2 - Loss: 0.09479033298984847, Correct: 0.9636526107788086\n",
      "Epoch 2 - Loss: 0.09090407808235619, Correct: 0.9644623398780823\n",
      "Epoch 2 - Loss: 0.09345408108393116, Correct: 0.9643106460571289\n",
      "Epoch 2 - Loss: 0.09745323071452067, Correct: 0.9621513485908508\n",
      "Epoch 2 - Loss: 0.09387012478200928, Correct: 0.9641912579536438\n",
      "Epoch 2 - Loss: 0.09292899844418608, Correct: 0.964715838432312\n",
      "Epoch 2 - Loss: 0.09164726928570904, Correct: 0.9648237228393555\n",
      "Epoch 2 - Loss: 0.09916326992487996, Correct: 0.9631811380386353\n",
      "Epoch 2 - Loss: 0.09445310723791318, Correct: 0.9634891748428345\n",
      "Epoch 2 - Loss: 0.10220144615339434, Correct: 0.9601786732673645\n",
      "Epoch 2 - Loss: 0.09805950308703461, Correct: 0.9624595046043396\n",
      "Epoch 2 - Loss: 0.08961279569868716, Correct: 0.966032087802887\n",
      "Epoch 2 - Loss: 0.09035441847302578, Correct: 0.9654878973960876\n",
      "Epoch 2 - Loss: 0.09544130195254097, Correct: 0.9636853337287903\n",
      "Epoch 2 - Loss: 0.09282160963008305, Correct: 0.9648335576057434\n",
      "Epoch 2 - Loss: 0.09440206025625197, Correct: 0.9638073444366455\n",
      "Epoch 2 - Loss: 0.09255315710324173, Correct: 0.9643315672874451\n",
      "Epoch 2 - Loss: 0.0953211597833032, Correct: 0.9637881517410278\n",
      "Epoch 2 - Loss: 0.09666682002665954, Correct: 0.964115560054779\n",
      "Epoch 2 - Loss: 0.0906886814958394, Correct: 0.9654290676116943\n",
      "Epoch 2 - Loss: 0.0975501354589838, Correct: 0.9632276892662048\n",
      "Epoch 2 - Loss: 0.09826828791285803, Correct: 0.9624900221824646\n",
      "Epoch 2 - Loss: 0.09531469056112275, Correct: 0.9634695053100586\n",
      "Epoch 2 - Loss: 0.09340052572092708, Correct: 0.9636175036430359\n",
      "Epoch 2 - Loss: 0.09080947851492707, Correct: 0.9648504257202148\n",
      "Epoch 2 - Loss: 0.09049462886461192, Correct: 0.9657790660858154\n",
      "Epoch 2 - Loss: 0.09245478160809399, Correct: 0.9649800062179565\n",
      "Epoch 2 - Loss: 0.09694220222989129, Correct: 0.9633955359458923\n",
      "Epoch 2 - Loss: 0.0964605404090859, Correct: 0.9629629850387573\n",
      "Epoch 2 - Loss: 0.09667563894320035, Correct: 0.9629631042480469\n",
      "Epoch 2 - Loss: 0.09747935799229213, Correct: 0.9627128839492798\n",
      "Epoch 2 - Loss: 0.09201288336867058, Correct: 0.9648292660713196\n",
      "Epoch 2 - Loss: 0.09621435890519342, Correct: 0.963405966758728\n",
      "Epoch 2 - Loss: 0.09670581681388396, Correct: 0.9638132452964783\n",
      "Epoch 2 - Loss: 0.0989408142026769, Correct: 0.9626111388206482\n",
      "Epoch 2 - Loss: 0.0975674275418393, Correct: 0.9634670615196228\n",
      "Epoch 2 - Loss: 0.09470060892449073, Correct: 0.9633702635765076\n",
      "Epoch 2 - Loss: 0.0959717695594297, Correct: 0.9634813666343689\n",
      "Epoch 2 - Loss: 0.09108521265735704, Correct: 0.965187132358551\n",
      "Epoch 2 - Loss: 0.09226657345852506, Correct: 0.9644672870635986\n",
      "Epoch 2 - Loss: 0.09906916544795585, Correct: 0.961103081703186\n",
      "Epoch 2 - Loss: 0.09688050679572813, Correct: 0.9632622599601746\n",
      "Epoch 2 - Loss: 0.09303165830030648, Correct: 0.9637311697006226\n",
      "Epoch 2 - Loss: 0.09780831792360559, Correct: 0.9631778001785278\n",
      "Epoch 2 - Loss: 0.09456602676745289, Correct: 0.9632641077041626\n",
      "Epoch 2 - Loss: 0.09226381998105314, Correct: 0.9641753435134888\n",
      "Epoch 2 - Loss: 0.09426401204407962, Correct: 0.965495228767395\n",
      "Epoch 2 - Loss: 0.09309245084678947, Correct: 0.9644018411636353\n",
      "Epoch 2 - Loss: 0.09227981038793548, Correct: 0.9640895128250122\n",
      "Epoch 2 - Loss: 0.0929686736869964, Correct: 0.9639202356338501\n",
      "Epoch 2 - Loss: 0.09443960434202434, Correct: 0.9634214043617249\n",
      "Epoch 2 - Loss: 0.09739908588365323, Correct: 0.9632216095924377\n",
      "Epoch 2 - Loss: 0.09092355671697443, Correct: 0.9650328159332275\n",
      "Epoch 2 - Loss: 0.1027599916773135, Correct: 0.9616096019744873\n",
      "Epoch 2 - Loss: 0.09552280534507027, Correct: 0.9639037847518921\n",
      "Epoch 2 - Loss: 0.0960285938199128, Correct: 0.9637874364852905\n",
      "Epoch 2 - Loss: 0.09434026483723632, Correct: 0.9636977910995483\n",
      "Epoch 2 - Loss: 0.09648198075574518, Correct: 0.9626303315162659\n",
      "Epoch 2 - Loss: 0.09641987517951128, Correct: 0.9635217785835266\n",
      "Epoch 2 - Loss: 0.09688734217808927, Correct: 0.9626958966255188\n",
      "Epoch 2 - Loss: 0.09320801432279319, Correct: 0.9644256234169006\n",
      "Epoch 2 - Loss: 0.09260219766007333, Correct: 0.9646779894828796\n",
      "Epoch 2 - Loss: 0.09288330909513734, Correct: 0.9641808867454529\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m act \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((_act[\u001b[39m0\u001b[39m], _add_data[\u001b[39m0\u001b[39m][:,\u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m]), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     13\u001b[0m add_data \u001b[39m=\u001b[39m _add_data[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m \u001b[39mif\u001b[39;00m obs\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     16\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gpumodel.train()\n",
    "\n",
    "for epoch in range(10):\n",
    "    batch = 0\n",
    "    total_loss = 0\n",
    "    obs_count = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for _obs, _act, _add_data in Train_Data_Loader:\n",
    "        # TRAINING \n",
    "        obs = _obs[0].cuda()\n",
    "        act = torch.cat((_act[0], _add_data[0][:,0:1]), dim=1).long().cuda()\n",
    "        add_data = _add_data[0]\n",
    "\n",
    "        if obs.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(obs)\n",
    "        pred_act = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "\n",
    "        loss = criterion(y_pred, act[:, TARGET])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # LOGGING\n",
    "        obs_count += len(obs)\n",
    "        total_loss += loss.item() * len(obs)\n",
    "\n",
    "        correct = act[:, TARGET] == pred_act\n",
    "        total_correct += torch.sum(correct, dim=0)\n",
    "\n",
    "\n",
    "        batch += 1\n",
    "        if batch % 1000 == 0:\n",
    "            idv_accuracy = total_correct/obs_count\n",
    "\n",
    "            print(f'Epoch {epoch + 1} - Loss: {total_loss / obs_count}, Correct: {idv_accuracy}')\n",
    "            # wandb.log({\"loss\": total_loss/obs_count, \"accuracy/throttle\": idv_accuracy[0], \"accuracy/steer\": idv_accuracy[1], \"accuracy/yaw\": idv_accuracy[2], \n",
    "            #             \"accuracy/pitch\": idv_accuracy[3], \"accuracy/roll\": idv_accuracy[4], \"accuracy/jump\": idv_accuracy[5], \"accuracy/boost\": idv_accuracy[6],\n",
    "            #             \"accuracy/handbrake\": idv_accuracy[7], \"accuracy/on_ground\": idv_accuracy[8]})\n",
    "\n",
    "            total_loss = 0\n",
    "            obs_count = 0\n",
    "            total_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39msave(gpumodel\u001b[39m.\u001b[39mstate_dict(), \u001b[39m\"\u001b[39m\u001b[39mtrained_networks/fc3_all_512x4_w_change_corrupt_w_og.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(gpumodel.state_dict(), \"trained_networks/single_throttle.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Episode Data\n",
      "Finished Loading Episode Data\n"
     ]
    }
   ],
   "source": [
    "#TEST_PATH = '/home/bdemoss/Desktop/RL IDM/Episode Data/Nexto Data/30 TPS/3v3 Test'\n",
    "#TEST_PATH = '/home/bdemoss/Desktop/RL IDM/Episode Data/Human Example Data/30 TPS'\n",
    "TEST_PATH = '/home/bdemoss/Desktop/RL IDM/Episode Data/Human Replays'\n",
    "\n",
    "test_dataset = EpisodeDataset([TEST_PATH], width=WIDTH, include_change=True, corrupt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data_Loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.46652787923812866, Correct: 0.8958847522735596\n",
      "[[ 173.   16.    8.]\n",
      " [  28.  804.   50.]\n",
      " [   4.  147. 1200.]]\n"
     ]
    }
   ],
   "source": [
    "conf_mtx = torch.zeros((3,3)).cuda()\n",
    "CONF_MAT = True\n",
    "\n",
    "gpumodel.eval()\n",
    "\n",
    "total_loss = 0\n",
    "obs_count = 0\n",
    "total_correct = 0\n",
    "\n",
    "correct_on_ground = torch.zeros(9).cuda()\n",
    "total_on_ground = 0\n",
    "\n",
    "for _obs, _act, _add_data in Test_Data_Loader:\n",
    "    # EVALUATION\n",
    "    obs = _obs[0].cuda()\n",
    "    act = torch.cat((_act[0], _add_data[0][:,0:1]), dim=1).long().cuda()\n",
    "    add_data = _add_data[0].long()\n",
    "\n",
    "    if obs.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(obs)\n",
    "\n",
    "    y_pred = model(obs)\n",
    "    pred_act = torch.argmax(y_pred, dim=1)\n",
    "\n",
    "\n",
    "    loss = criterion(y_pred, act[:, TARGET])\n",
    "\n",
    "\n",
    "    # LOGGING\n",
    "    obs_count += len(obs)\n",
    "    total_loss += loss.item() * len(obs)\n",
    "\n",
    "    correct = act[:, TARGET] == pred_act\n",
    "\n",
    "    total_correct += torch.sum(correct, dim=0)\n",
    "\n",
    "    if CONF_MAT:\n",
    "        for i in range(obs.shape[0]):\n",
    "            conf_mtx[act[i, TARGET], pred_act[i].long()] += 1\n",
    "\n",
    "    \n",
    "\n",
    "print(f'Loss: {total_loss / obs_count}, Correct: {total_correct / obs_count}')\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "print((conf_mtx).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(pred_act)\n",
    "print(act[:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLGym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "baa0d24347c96f08397175d5f5df5429dcdfcaeab02cd215c26c77f2399e651c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
